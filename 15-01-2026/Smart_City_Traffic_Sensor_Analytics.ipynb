{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CASE STUDY 4\n",
        "Title: Smart City Traffic Sensor Analytics using PySpark"
      ],
      "metadata": {
        "id": "98bCPm3UIQio"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PHASE 1 – Ingestion\n",
        "1. Read traffic_data.csv as StringType.\n",
        "\n",
        "2. Print schema and count records.\n",
        "3. Identify data quality issues by inspection."
      ],
      "metadata": {
        "id": "M7MN7jgtIXue"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "HqTGfC-6Frej"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import StringType\n",
        "\n",
        "spark=SparkSession.builder.appName('SmartCityTrafficAnalytics').getOrCreate()\n",
        "\n",
        "df_raw=spark.read.csv('traffic_data_large.csv',header=True,inferSchema=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_raw.printSchema()\n",
        "df_raw.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaAVbaGnJFEM",
        "outputId": "3715bf9f-4baf-4cd7-a1f3-9ca2e78338f4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- sensor_id: string (nullable = true)\n",
            " |-- location: string (nullable = true)\n",
            " |-- road_name: string (nullable = true)\n",
            " |-- vehicle_count: string (nullable = true)\n",
            " |-- avg_speed: string (nullable = true)\n",
            " |-- temperature: string (nullable = true)\n",
            " |-- timestamp: string (nullable = true)\n",
            " |-- status: string (nullable = true)\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500000"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce3ea2aa",
        "outputId": "1d57a633-4e22-4e01-a189-5e5ff89c3f41"
      },
      "source": [
        "df_raw.show(5)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+---------------+-------------+---------+-----------+-------------------+--------+\n",
            "|sensor_id| location|      road_name|vehicle_count|avg_speed|temperature|          timestamp|  status|\n",
            "+---------+---------+---------------+-------------+---------+-----------+-------------------+--------+\n",
            "|     S105|  Chennai|            OMR|      invalid|     NULL|         39|12/01/2026 06:00:00|INACTIVE|\n",
            "|     S113|  Chennai|     Mount Road|          103|     73.5|         36|2026-01-12 06:00:05|  ACTIVE|\n",
            "|     S228|    Delhi|        Janpath|           16|     20.0|         35|2026-01-12 06:00:10|  ACTIVE|\n",
            "|     S160|Bangalore|        MG Road|           27|     27.1|         32|2026-01-12 06:00:15|  ACTIVE|\n",
            "|     S252|   Mumbai|Western Express|          115|     59.3|         39|2026-01-12 06:00:20|  ACTIVE|\n",
            "+---------+---------+---------------+-------------+---------+-----------+-------------------+--------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Incorrect Data Types: All columns are currently inferred as StringType, but columns like vehicle_count, avg_speed, temperature, and timestamp should be numerical or datetime types for proper analysis.\n",
        "2. Invalid Values: In the vehicle_count column, there's a value 'invalid' (e.g., in sensor_id S105), which is not a valid numerical entry.\n",
        "3. Missing Values Represented as Strings: In the avg_speed column, there's a 'NULL' string value (e.g., in sensor_id S105) instead of a proper null or numerical value.\n",
        "4. Inconsistent Timestamp Format: The timestamp column shows at least two different formats (MM/dd/yyyy HH:mm:ss and yyyy-MM-dd HH:mm:ss), which will make direct conversion to a datetime type problematic."
      ],
      "metadata": {
        "id": "fSnl-YMwJtDg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PHASE 2 – Cleaning\n",
        "1. Trim all string columns.\n",
        "2. Clean vehicle_count:\n",
        "Replace invalid and empty with null\n",
        "Cast to IntegerType\n",
        "3. Clean avg_speed:\n",
        "Replace empty with null\n",
        "Cast to DoubleType\n",
        "4. Parse timestamp into:\n",
        "\n",
        "event_time\n",
        "\n",
        "with TimestampType supporting:\n",
        "yyyy-MM-dd HH:mm:ss\n",
        "dd/MM/yyyy HH:mm:ss\n",
        "yyyy/MM/dd HH:mm:ss\n",
        "\n",
        "5. Keep original timestamp for audit."
      ],
      "metadata": {
        "id": "c3D4ceXTJ4sd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_trimmed=df_raw.select(\n",
        "    [\n",
        "        trim(col(c)).alias(c) for c in df_raw.columns\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "Dnh_y_cPJ0MF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean=df_trimmed.withColumn(\n",
        "    \"vehicle_count_clean\",\n",
        "    when(col(\"vehicle_count\").rlike(\"^[0-9]+$\"),col(\"vehicle_count\").cast(\"int\")).otherwise(None)\n",
        ")\n"
      ],
      "metadata": {
        "id": "lhS5aCU9KQ2y"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean=df_clean.withColumn(\n",
        "    \"avg_speed_clean\",\n",
        "    when(col(\"avg_speed\")!=\"\",col(\"avg_speed\").cast(\"double\")).otherwise(None)\n",
        ")\n"
      ],
      "metadata": {
        "id": "cKR4dAorKnpQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean=df_clean.withColumn(\n",
        "    \"event_time\",\n",
        "    coalesce(\n",
        "        try_to_timestamp(col(\"timestamp\"),lit(\"yyyy-MM-dd HH:mm:ss\")),\n",
        "        try_to_timestamp(col(\"timestamp\"),lit(\"dd/MM/yyyy HH:mm:ss\")),\n",
        "        try_to_timestamp(col(\"timestamp\"),lit(\"yyyy/MM/dd HH:mm:ss\"))\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "YmElEtLVKz4C"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PHASE 3 – Validation\n",
        "1. Count invalid vehicle_count rows.\n",
        "2. Count invalid timestamp rows.\n",
        "3. Remove rows where:\n",
        "\n",
        "status != \"ACTIVE\"\n",
        "\n",
        "4. Validate row counts."
      ],
      "metadata": {
        "id": "yK3W1tVWLj_T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean.filter(col(\"vehicle_count_clean\").isNull()).count()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNxR2OYGLfF-",
        "outputId": "c23ff915-ccc3-48ac-c026-ae371f57269c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49873"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_active=df_clean.filter(col(\"status\")==\"ACTIVE\")\n",
        "df_active.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coAzKaxLLvWF",
        "outputId": "796aa0a6-78bd-45e1-93f3-4a3f490b695a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "475000"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_raw.count()-df_active.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wh8NsYV9L4SP",
        "outputId": "7ef62e8c-4dce-4e1c-e90a-5b515e235a17"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25000"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PHASE 4 – Traffic Metrics\n",
        "1. Average speed per location.\n",
        "2. Total vehicle count per road.\n",
        "\n",
        "3. Peak traffic time per location.\n",
        "4. Roads with lowest average speed (most congestion)."
      ],
      "metadata": {
        "id": "tNOcPkrbMDOc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "avg_speed_location=df_active.groupBy(\"location\").agg(avg(\"avg_speed_clean\").alias(\"avg_speed\"))\n"
      ],
      "metadata": {
        "id": "teV5tCz7L-Y3"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vehicle_per_road=df_active.groupBy(\"road_name\").agg(sum(\"vehicle_count_clean\").alias(\"total_vehicles\"))"
      ],
      "metadata": {
        "id": "zUODd0jUMM61"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "peak_time=df_active.groupBy(\"location\").agg(\n",
        "    max(\"event_time\").alias(\"peak_event_time\"),\n",
        "    sum(\"vehicle_count_clean\").alias(\"vehicles\")\n",
        ")"
      ],
      "metadata": {
        "id": "ZlcwHN33MW9Q"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "congested_roads=df_active.groupBy(\"road_name\").agg(avg(\"avg_speed_clean\").alias(\"avg_speed\")).orderBy(\"avg_speed\")"
      ],
      "metadata": {
        "id": "pPVuUDkyM9Q5"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PHASE 5 – Window Functions\n",
        "1. Rank roads by congestion (lowest speed).\n",
        "2. For each location, rank roads by vehicle_count.\n",
        "3. Identify top 3 congested roads per location."
      ],
      "metadata": {
        "id": "eT7S87z3NM9h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.window import Window"
      ],
      "metadata": {
        "id": "Hof82by9NNt1"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w=Window.orderBy(\"avg_speed\")\n",
        "congestion_rank=congested_roads.withColumn(\"congestion_rank\",dense_rank().over(w))"
      ],
      "metadata": {
        "id": "umangLzqNRAn"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w_loc=Window.partitionBy(\"location\").orderBy(desc(\"vehicle_count_clean\"))\n",
        "ranked_roads=df_active.withColumn(\"road_rank\",dense_rank().over(w_loc))"
      ],
      "metadata": {
        "id": "dBzex8JjNahr"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_3_congested=ranked_roads.filter(col(\"road_rank\")<=3)"
      ],
      "metadata": {
        "id": "a_7z9aaXNrjg"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PHASE 6 – Anomaly Detection\n",
        "1. Detect sudden drop in avg_speed.\n",
        "2. Detect sudden spikes in vehicle_count.\n",
        "3. Use:\n",
        "\n",
        "lag()\n",
        "\n",
        "window function to compare with previous event."
      ],
      "metadata": {
        "id": "zZEplf6FN5Gw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w_sensor=Window.partitionBy(\"sensor_id\").orderBy(\"event_time\")"
      ],
      "metadata": {
        "id": "YfK8TVnkNvow"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_anomaly=df_active.withColumn(\n",
        "    \"prev_speed\",lag(\"avg_speed_clean\").over(w_sensor)\n",
        ").withColumn(\n",
        "    \"speed_drop\",\n",
        "    when(col(\"avg_speed_clean\")<col(\"prev_speed\")*0.7,True).otherwise(False)\n",
        ")"
      ],
      "metadata": {
        "id": "NZhkbokHN_cA"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_anomaly=df_anomaly.withColumn(\n",
        "    \"prev_count\",lag(\"vehicle_count_clean\").over(w_sensor)\n",
        ").withColumn(\n",
        "    \"vehicle_spike\",\n",
        "    when(col(\"vehicle_count_clean\")>col(\"prev_count\")*1.5,True).otherwise(False)\n",
        ")"
      ],
      "metadata": {
        "id": "BXOyp6CQOWUg"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PHASE 7 – Performance Engineering\n",
        "1. Check number of partitions.\n",
        "2. Use explain(True) on congestion queries.\n",
        "3. Repartition by location.\n",
        "4. Cache cleaned DataFrame.\n",
        "5. Compare execution plans."
      ],
      "metadata": {
        "id": "vuRMxT91On1g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_active.rdd.getNumPartitions()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3BXy9jwOlK_",
        "outputId": "3e833917-206e-432c-908e-6a7e91dc7b8e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "congested_roads.explain(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6ntRWQ6OsiX",
        "outputId": "5e697fd7-e0e9-4dc4-a2e7-adc4a86814fa"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Parsed Logical Plan ==\n",
            "'Sort ['avg_speed ASC NULLS FIRST], true\n",
            "+- Aggregate [road_name#73], [road_name#73, avg(avg_speed_clean#80) AS avg_speed#199]\n",
            "   +- Filter (status#78 = ACTIVE)\n",
            "      +- Project [sensor_id#71, location#72, road_name#73, vehicle_count#74, avg_speed#75, temperature#76, timestamp#77, status#78, vehicle_count_clean#79, avg_speed_clean#80, coalesce(try_to_timestamp(timestamp#77, Some(yyyy-MM-dd HH:mm:ss), TimestampType, Some(Etc/UTC), false), try_to_timestamp(timestamp#77, Some(dd/MM/yyyy HH:mm:ss), TimestampType, Some(Etc/UTC), false), try_to_timestamp(timestamp#77, Some(yyyy/MM/dd HH:mm:ss), TimestampType, Some(Etc/UTC), false)) AS event_time#81]\n",
            "         +- Project [sensor_id#71, location#72, road_name#73, vehicle_count#74, avg_speed#75, temperature#76, timestamp#77, status#78, vehicle_count_clean#79, CASE WHEN NOT (avg_speed#75 = ) THEN cast(avg_speed#75 as double) ELSE cast(null as double) END AS avg_speed_clean#80]\n",
            "            +- Project [sensor_id#71, location#72, road_name#73, vehicle_count#74, avg_speed#75, temperature#76, timestamp#77, status#78, CASE WHEN RLIKE(vehicle_count#74, ^[0-9]+$) THEN cast(vehicle_count#74 as int) ELSE cast(null as int) END AS vehicle_count_clean#79]\n",
            "               +- Project [trim(sensor_id#17, None) AS sensor_id#71, trim(location#18, None) AS location#72, trim(road_name#19, None) AS road_name#73, trim(vehicle_count#20, None) AS vehicle_count#74, trim(avg_speed#21, None) AS avg_speed#75, trim(temperature#22, None) AS temperature#76, trim(timestamp#23, None) AS timestamp#77, trim(status#24, None) AS status#78]\n",
            "                  +- Relation [sensor_id#17,location#18,road_name#19,vehicle_count#20,avg_speed#21,temperature#22,timestamp#23,status#24] csv\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "road_name: string, avg_speed: double\n",
            "Sort [avg_speed#199 ASC NULLS FIRST], true\n",
            "+- Aggregate [road_name#73], [road_name#73, avg(avg_speed_clean#80) AS avg_speed#199]\n",
            "   +- Filter (status#78 = ACTIVE)\n",
            "      +- Project [sensor_id#71, location#72, road_name#73, vehicle_count#74, avg_speed#75, temperature#76, timestamp#77, status#78, vehicle_count_clean#79, avg_speed_clean#80, coalesce(try_to_timestamp(timestamp#77, Some(yyyy-MM-dd HH:mm:ss), TimestampType, Some(Etc/UTC), false), try_to_timestamp(timestamp#77, Some(dd/MM/yyyy HH:mm:ss), TimestampType, Some(Etc/UTC), false), try_to_timestamp(timestamp#77, Some(yyyy/MM/dd HH:mm:ss), TimestampType, Some(Etc/UTC), false)) AS event_time#81]\n",
            "         +- Project [sensor_id#71, location#72, road_name#73, vehicle_count#74, avg_speed#75, temperature#76, timestamp#77, status#78, vehicle_count_clean#79, CASE WHEN NOT (avg_speed#75 = ) THEN cast(avg_speed#75 as double) ELSE cast(null as double) END AS avg_speed_clean#80]\n",
            "            +- Project [sensor_id#71, location#72, road_name#73, vehicle_count#74, avg_speed#75, temperature#76, timestamp#77, status#78, CASE WHEN RLIKE(vehicle_count#74, ^[0-9]+$) THEN cast(vehicle_count#74 as int) ELSE cast(null as int) END AS vehicle_count_clean#79]\n",
            "               +- Project [trim(sensor_id#17, None) AS sensor_id#71, trim(location#18, None) AS location#72, trim(road_name#19, None) AS road_name#73, trim(vehicle_count#20, None) AS vehicle_count#74, trim(avg_speed#21, None) AS avg_speed#75, trim(temperature#22, None) AS temperature#76, trim(timestamp#23, None) AS timestamp#77, trim(status#24, None) AS status#78]\n",
            "                  +- Relation [sensor_id#17,location#18,road_name#19,vehicle_count#20,avg_speed#21,temperature#22,timestamp#23,status#24] csv\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Sort [avg_speed#199 ASC NULLS FIRST], true\n",
            "+- Aggregate [road_name#73], [road_name#73, avg(avg_speed_clean#80) AS avg_speed#199]\n",
            "   +- Project [road_name#73, CASE WHEN NOT (avg_speed#75 = ) THEN cast(avg_speed#75 as double) END AS avg_speed_clean#80]\n",
            "      +- Project [trim(road_name#19, None) AS road_name#73, trim(avg_speed#21, None) AS avg_speed#75]\n",
            "         +- Filter (trim(status#24, None) = ACTIVE)\n",
            "            +- Relation [sensor_id#17,location#18,road_name#19,vehicle_count#20,avg_speed#21,temperature#22,timestamp#23,status#24] csv\n",
            "\n",
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- Sort [avg_speed#199 ASC NULLS FIRST], true, 0\n",
            "   +- Exchange rangepartitioning(avg_speed#199 ASC NULLS FIRST, 200), ENSURE_REQUIREMENTS, [plan_id=270]\n",
            "      +- HashAggregate(keys=[road_name#73], functions=[avg(avg_speed_clean#80)], output=[road_name#73, avg_speed#199])\n",
            "         +- Exchange hashpartitioning(road_name#73, 200), ENSURE_REQUIREMENTS, [plan_id=267]\n",
            "            +- HashAggregate(keys=[road_name#73], functions=[partial_avg(avg_speed_clean#80)], output=[road_name#73, sum#244, count#245L])\n",
            "               +- Project [road_name#73, CASE WHEN NOT (avg_speed#75 = ) THEN cast(avg_speed#75 as double) END AS avg_speed_clean#80]\n",
            "                  +- Project [trim(road_name#19, None) AS road_name#73, trim(avg_speed#21, None) AS avg_speed#75]\n",
            "                     +- Filter (trim(status#24, None) = ACTIVE)\n",
            "                        +- FileScan csv [road_name#19,avg_speed#21,status#24] Batched: false, DataFilters: [(trim(status#24, None) = ACTIVE)], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/content/traffic_data_large.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<road_name:string,avg_speed:string,status:string>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_perf=df_active.repartition(\"location\")"
      ],
      "metadata": {
        "id": "qRaXoZuHOxy8"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_perf.cache()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOuRtWFGO36G",
        "outputId": "ca195b7e-8739-4d42-af0d-f730068f005f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[sensor_id: string, location: string, road_name: string, vehicle_count: string, avg_speed: string, temperature: string, timestamp: string, status: string, vehicle_count_clean: int, avg_speed_clean: double, event_time: timestamp]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_active.explain(True)\n",
        "df_perf.explain(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOXp6l5pO60O",
        "outputId": "1145029d-c1f9-46ed-a6c5-fdbff5234b8d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Parsed Logical Plan ==\n",
            "'Filter '`=`('status, ACTIVE)\n",
            "+- Project [sensor_id#71, location#72, road_name#73, vehicle_count#74, avg_speed#75, temperature#76, timestamp#77, status#78, vehicle_count_clean#79, avg_speed_clean#80, coalesce(try_to_timestamp(timestamp#77, Some(yyyy-MM-dd HH:mm:ss), TimestampType, Some(Etc/UTC), false), try_to_timestamp(timestamp#77, Some(dd/MM/yyyy HH:mm:ss), TimestampType, Some(Etc/UTC), false), try_to_timestamp(timestamp#77, Some(yyyy/MM/dd HH:mm:ss), TimestampType, Some(Etc/UTC), false)) AS event_time#81]\n",
            "   +- Project [sensor_id#71, location#72, road_name#73, vehicle_count#74, avg_speed#75, temperature#76, timestamp#77, status#78, vehicle_count_clean#79, CASE WHEN NOT (avg_speed#75 = ) THEN cast(avg_speed#75 as double) ELSE cast(null as double) END AS avg_speed_clean#80]\n",
            "      +- Project [sensor_id#71, location#72, road_name#73, vehicle_count#74, avg_speed#75, temperature#76, timestamp#77, status#78, CASE WHEN RLIKE(vehicle_count#74, ^[0-9]+$) THEN cast(vehicle_count#74 as int) ELSE cast(null as int) END AS vehicle_count_clean#79]\n",
            "         +- Project [trim(sensor_id#17, None) AS sensor_id#71, trim(location#18, None) AS location#72, trim(road_name#19, None) AS road_name#73, trim(vehicle_count#20, None) AS vehicle_count#74, trim(avg_speed#21, None) AS avg_speed#75, trim(temperature#22, None) AS temperature#76, trim(timestamp#23, None) AS timestamp#77, trim(status#24, None) AS status#78]\n",
            "            +- Relation [sensor_id#17,location#18,road_name#19,vehicle_count#20,avg_speed#21,temperature#22,timestamp#23,status#24] csv\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "sensor_id: string, location: string, road_name: string, vehicle_count: string, avg_speed: string, temperature: string, timestamp: string, status: string, vehicle_count_clean: int, avg_speed_clean: double, event_time: timestamp\n",
            "Filter (status#78 = ACTIVE)\n",
            "+- Project [sensor_id#71, location#72, road_name#73, vehicle_count#74, avg_speed#75, temperature#76, timestamp#77, status#78, vehicle_count_clean#79, avg_speed_clean#80, coalesce(try_to_timestamp(timestamp#77, Some(yyyy-MM-dd HH:mm:ss), TimestampType, Some(Etc/UTC), false), try_to_timestamp(timestamp#77, Some(dd/MM/yyyy HH:mm:ss), TimestampType, Some(Etc/UTC), false), try_to_timestamp(timestamp#77, Some(yyyy/MM/dd HH:mm:ss), TimestampType, Some(Etc/UTC), false)) AS event_time#81]\n",
            "   +- Project [sensor_id#71, location#72, road_name#73, vehicle_count#74, avg_speed#75, temperature#76, timestamp#77, status#78, vehicle_count_clean#79, CASE WHEN NOT (avg_speed#75 = ) THEN cast(avg_speed#75 as double) ELSE cast(null as double) END AS avg_speed_clean#80]\n",
            "      +- Project [sensor_id#71, location#72, road_name#73, vehicle_count#74, avg_speed#75, temperature#76, timestamp#77, status#78, CASE WHEN RLIKE(vehicle_count#74, ^[0-9]+$) THEN cast(vehicle_count#74 as int) ELSE cast(null as int) END AS vehicle_count_clean#79]\n",
            "         +- Project [trim(sensor_id#17, None) AS sensor_id#71, trim(location#18, None) AS location#72, trim(road_name#19, None) AS road_name#73, trim(vehicle_count#20, None) AS vehicle_count#74, trim(avg_speed#21, None) AS avg_speed#75, trim(temperature#22, None) AS temperature#76, trim(timestamp#23, None) AS timestamp#77, trim(status#24, None) AS status#78]\n",
            "            +- Relation [sensor_id#17,location#18,road_name#19,vehicle_count#20,avg_speed#21,temperature#22,timestamp#23,status#24] csv\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Project [sensor_id#71, location#72, road_name#73, vehicle_count#74, avg_speed#75, temperature#76, timestamp#77, status#78, CASE WHEN RLIKE(vehicle_count#74, ^[0-9]+$) THEN cast(vehicle_count#74 as int) END AS vehicle_count_clean#79, CASE WHEN NOT (avg_speed#75 = ) THEN cast(avg_speed#75 as double) END AS avg_speed_clean#80, coalesce(gettimestamp(timestamp#77, yyyy-MM-dd HH:mm:ss, TimestampType, try_to_timestamp, Some(Etc/UTC), false), gettimestamp(timestamp#77, dd/MM/yyyy HH:mm:ss, TimestampType, try_to_timestamp, Some(Etc/UTC), false), gettimestamp(timestamp#77, yyyy/MM/dd HH:mm:ss, TimestampType, try_to_timestamp, Some(Etc/UTC), false)) AS event_time#81]\n",
            "+- Project [trim(sensor_id#17, None) AS sensor_id#71, trim(location#18, None) AS location#72, trim(road_name#19, None) AS road_name#73, trim(vehicle_count#20, None) AS vehicle_count#74, trim(avg_speed#21, None) AS avg_speed#75, trim(temperature#22, None) AS temperature#76, trim(timestamp#23, None) AS timestamp#77, trim(status#24, None) AS status#78]\n",
            "   +- Filter (trim(status#24, None) = ACTIVE)\n",
            "      +- Relation [sensor_id#17,location#18,road_name#19,vehicle_count#20,avg_speed#21,temperature#22,timestamp#23,status#24] csv\n",
            "\n",
            "== Physical Plan ==\n",
            "*(1) Project [sensor_id#71, location#72, road_name#73, vehicle_count#74, avg_speed#75, temperature#76, timestamp#77, status#78, CASE WHEN RLIKE(vehicle_count#74, ^[0-9]+$) THEN cast(vehicle_count#74 as int) END AS vehicle_count_clean#79, CASE WHEN NOT (avg_speed#75 = ) THEN cast(avg_speed#75 as double) END AS avg_speed_clean#80, coalesce(gettimestamp(timestamp#77, yyyy-MM-dd HH:mm:ss, TimestampType, try_to_timestamp, Some(Etc/UTC), false), gettimestamp(timestamp#77, dd/MM/yyyy HH:mm:ss, TimestampType, try_to_timestamp, Some(Etc/UTC), false), gettimestamp(timestamp#77, yyyy/MM/dd HH:mm:ss, TimestampType, try_to_timestamp, Some(Etc/UTC), false)) AS event_time#81]\n",
            "+- *(1) Project [trim(sensor_id#17, None) AS sensor_id#71, trim(location#18, None) AS location#72, trim(road_name#19, None) AS road_name#73, trim(vehicle_count#20, None) AS vehicle_count#74, trim(avg_speed#21, None) AS avg_speed#75, trim(temperature#22, None) AS temperature#76, trim(timestamp#23, None) AS timestamp#77, trim(status#24, None) AS status#78]\n",
            "   +- *(1) Filter (trim(status#24, None) = ACTIVE)\n",
            "      +- FileScan csv [sensor_id#17,location#18,road_name#19,vehicle_count#20,avg_speed#21,temperature#22,timestamp#23,status#24] Batched: false, DataFilters: [(trim(status#24, None) = ACTIVE)], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/content/traffic_data_large.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<sensor_id:string,location:string,road_name:string,vehicle_count:string,avg_speed:string,te...\n",
            "\n",
            "== Parsed Logical Plan ==\n",
            "'RepartitionByExpression ['location]\n",
            "+- Filter (status#78 = ACTIVE)\n",
            "   +- Project [sensor_id#71, location#72, road_name#73, vehicle_count#74, avg_speed#75, temperature#76, timestamp#77, status#78, vehicle_count_clean#79, avg_speed_clean#80, coalesce(try_to_timestamp(timestamp#77, Some(yyyy-MM-dd HH:mm:ss), TimestampType, Some(Etc/UTC), false), try_to_timestamp(timestamp#77, Some(dd/MM/yyyy HH:mm:ss), TimestampType, Some(Etc/UTC), false), try_to_timestamp(timestamp#77, Some(yyyy/MM/dd HH:mm:ss), TimestampType, Some(Etc/UTC), false)) AS event_time#81]\n",
            "      +- Project [sensor_id#71, location#72, road_name#73, vehicle_count#74, avg_speed#75, temperature#76, timestamp#77, status#78, vehicle_count_clean#79, CASE WHEN NOT (avg_speed#75 = ) THEN cast(avg_speed#75 as double) ELSE cast(null as double) END AS avg_speed_clean#80]\n",
            "         +- Project [sensor_id#71, location#72, road_name#73, vehicle_count#74, avg_speed#75, temperature#76, timestamp#77, status#78, CASE WHEN RLIKE(vehicle_count#74, ^[0-9]+$) THEN cast(vehicle_count#74 as int) ELSE cast(null as int) END AS vehicle_count_clean#79]\n",
            "            +- Project [trim(sensor_id#17, None) AS sensor_id#71, trim(location#18, None) AS location#72, trim(road_name#19, None) AS road_name#73, trim(vehicle_count#20, None) AS vehicle_count#74, trim(avg_speed#21, None) AS avg_speed#75, trim(temperature#22, None) AS temperature#76, trim(timestamp#23, None) AS timestamp#77, trim(status#24, None) AS status#78]\n",
            "               +- Relation [sensor_id#17,location#18,road_name#19,vehicle_count#20,avg_speed#21,temperature#22,timestamp#23,status#24] csv\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "sensor_id: string, location: string, road_name: string, vehicle_count: string, avg_speed: string, temperature: string, timestamp: string, status: string, vehicle_count_clean: int, avg_speed_clean: double, event_time: timestamp\n",
            "RepartitionByExpression [location#72]\n",
            "+- Filter (status#78 = ACTIVE)\n",
            "   +- Project [sensor_id#71, location#72, road_name#73, vehicle_count#74, avg_speed#75, temperature#76, timestamp#77, status#78, vehicle_count_clean#79, avg_speed_clean#80, coalesce(try_to_timestamp(timestamp#77, Some(yyyy-MM-dd HH:mm:ss), TimestampType, Some(Etc/UTC), false), try_to_timestamp(timestamp#77, Some(dd/MM/yyyy HH:mm:ss), TimestampType, Some(Etc/UTC), false), try_to_timestamp(timestamp#77, Some(yyyy/MM/dd HH:mm:ss), TimestampType, Some(Etc/UTC), false)) AS event_time#81]\n",
            "      +- Project [sensor_id#71, location#72, road_name#73, vehicle_count#74, avg_speed#75, temperature#76, timestamp#77, status#78, vehicle_count_clean#79, CASE WHEN NOT (avg_speed#75 = ) THEN cast(avg_speed#75 as double) ELSE cast(null as double) END AS avg_speed_clean#80]\n",
            "         +- Project [sensor_id#71, location#72, road_name#73, vehicle_count#74, avg_speed#75, temperature#76, timestamp#77, status#78, CASE WHEN RLIKE(vehicle_count#74, ^[0-9]+$) THEN cast(vehicle_count#74 as int) ELSE cast(null as int) END AS vehicle_count_clean#79]\n",
            "            +- Project [trim(sensor_id#17, None) AS sensor_id#71, trim(location#18, None) AS location#72, trim(road_name#19, None) AS road_name#73, trim(vehicle_count#20, None) AS vehicle_count#74, trim(avg_speed#21, None) AS avg_speed#75, trim(temperature#22, None) AS temperature#76, trim(timestamp#23, None) AS timestamp#77, trim(status#24, None) AS status#78]\n",
            "               +- Relation [sensor_id#17,location#18,road_name#19,vehicle_count#20,avg_speed#21,temperature#22,timestamp#23,status#24] csv\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "InMemoryRelation [sensor_id#71, location#72, road_name#73, vehicle_count#74, avg_speed#75, temperature#76, timestamp#77, status#78, vehicle_count_clean#79, avg_speed_clean#80, event_time#81], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "   +- AdaptiveSparkPlan isFinalPlan=false\n",
            "      +- Exchange hashpartitioning(location#72, 200), REPARTITION_BY_COL, [plan_id=286]\n",
            "         +- Project [sensor_id#71, location#72, road_name#73, vehicle_count#74, avg_speed#75, temperature#76, timestamp#77, status#78, CASE WHEN RLIKE(vehicle_count#74, ^[0-9]+$) THEN cast(vehicle_count#74 as int) END AS vehicle_count_clean#79, CASE WHEN NOT (avg_speed#75 = ) THEN cast(avg_speed#75 as double) END AS avg_speed_clean#80, coalesce(gettimestamp(timestamp#77, yyyy-MM-dd HH:mm:ss, TimestampType, try_to_timestamp, Some(Etc/UTC), false), gettimestamp(timestamp#77, dd/MM/yyyy HH:mm:ss, TimestampType, try_to_timestamp, Some(Etc/UTC), false), gettimestamp(timestamp#77, yyyy/MM/dd HH:mm:ss, TimestampType, try_to_timestamp, Some(Etc/UTC), false)) AS event_time#81]\n",
            "            +- Project [trim(sensor_id#17, None) AS sensor_id#71, trim(location#18, None) AS location#72, trim(road_name#19, None) AS road_name#73, trim(vehicle_count#20, None) AS vehicle_count#74, trim(avg_speed#21, None) AS avg_speed#75, trim(temperature#22, None) AS temperature#76, trim(timestamp#23, None) AS timestamp#77, trim(status#24, None) AS status#78]\n",
            "               +- Filter (trim(status#24, None) = ACTIVE)\n",
            "                  +- FileScan csv [sensor_id#17,location#18,road_name#19,vehicle_count#20,avg_speed#21,temperature#22,timestamp#23,status#24] Batched: false, DataFilters: [(trim(status#24, None) = ACTIVE)], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/content/traffic_data_large.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<sensor_id:string,location:string,road_name:string,vehicle_count:string,avg_speed:string,te...\n",
            "\n",
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- InMemoryTableScan [sensor_id#71, location#72, road_name#73, vehicle_count#74, avg_speed#75, temperature#76, timestamp#77, status#78, vehicle_count_clean#79, avg_speed_clean#80, event_time#81]\n",
            "      +- InMemoryRelation [sensor_id#71, location#72, road_name#73, vehicle_count#74, avg_speed#75, temperature#76, timestamp#77, status#78, vehicle_count_clean#79, avg_speed_clean#80, event_time#81], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "            +- AdaptiveSparkPlan isFinalPlan=false\n",
            "               +- Exchange hashpartitioning(location#72, 200), REPARTITION_BY_COL, [plan_id=286]\n",
            "                  +- Project [sensor_id#71, location#72, road_name#73, vehicle_count#74, avg_speed#75, temperature#76, timestamp#77, status#78, CASE WHEN RLIKE(vehicle_count#74, ^[0-9]+$) THEN cast(vehicle_count#74 as int) END AS vehicle_count_clean#79, CASE WHEN NOT (avg_speed#75 = ) THEN cast(avg_speed#75 as double) END AS avg_speed_clean#80, coalesce(gettimestamp(timestamp#77, yyyy-MM-dd HH:mm:ss, TimestampType, try_to_timestamp, Some(Etc/UTC), false), gettimestamp(timestamp#77, dd/MM/yyyy HH:mm:ss, TimestampType, try_to_timestamp, Some(Etc/UTC), false), gettimestamp(timestamp#77, yyyy/MM/dd HH:mm:ss, TimestampType, try_to_timestamp, Some(Etc/UTC), false)) AS event_time#81]\n",
            "                     +- Project [trim(sensor_id#17, None) AS sensor_id#71, trim(location#18, None) AS location#72, trim(road_name#19, None) AS road_name#73, trim(vehicle_count#20, None) AS vehicle_count#74, trim(avg_speed#21, None) AS avg_speed#75, trim(temperature#22, None) AS temperature#76, trim(timestamp#23, None) AS timestamp#77, trim(status#24, None) AS status#78]\n",
            "                        +- Filter (trim(status#24, None) = ACTIVE)\n",
            "                           +- FileScan csv [sensor_id#17,location#18,road_name#19,vehicle_count#20,avg_speed#21,temperature#22,timestamp#23,status#24] Batched: false, DataFilters: [(trim(status#24, None) = ACTIVE)], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/content/traffic_data_large.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<sensor_id:string,location:string,road_name:string,vehicle_count:string,avg_speed:string,te...\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PHASE 8 – RDD\n",
        "1. Convert cleaned DataFrame to RDD.\n",
        "2. Compute:\n",
        "Total vehicle count using reduce.\n",
        "Count of records per location using map-reduce.\n",
        "3. Explain why DataFrames are better for this case."
      ],
      "metadata": {
        "id": "VmO68l-KPERG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd=df_active.rdd"
      ],
      "metadata": {
        "id": "wLOUU6Y5PAP0"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_vehicles=rdd.map(lambda x:x.vehicle_count_clean or 0).reduce(lambda a,b:a+b)"
      ],
      "metadata": {
        "id": "Fdd_iyMxPIr9"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "location_count=rdd.map(lambda x:(x.location,1)).reduceByKey(lambda a,b:a+b)"
      ],
      "metadata": {
        "id": "iXOBeysGPdlA"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DataFrames are better due to:\n",
        "\n",
        "Optimized Execution: Spark's Catalyst Optimizer makes DataFrames much faster.\n",
        "\n",
        "Schema Awareness: Built-in schema allows for better validation, type safety, and optimization.\n",
        "\n",
        "Easier API: More intuitive and SQL-like operations simplify complex tasks.\n",
        "\n",
        "Performance with Structured Data: Highly efficient for structured data like our traffic sensor readings.\n",
        "\n",
        "Better Integration: Seamlessly works with other Spark libraries like MLlib and Spark SQL."
      ],
      "metadata": {
        "id": "2EDelTWMP_U8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PHASE 9 – Sorting & Set Operations\n",
        "1. Sort roads by highest congestion.\n",
        "2. Create two sets:\n",
        "\n",
        "Roads with avg_speed < 25\n",
        "Roads with vehicle_count > 60\n",
        "3. Find:\n",
        "Roads in both sets\n",
        "Roads in only one set"
      ],
      "metadata": {
        "id": "pRb8fnU7Psa2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_roads=congested_roads.orderBy(asc(\"avg_speed\"))"
      ],
      "metadata": {
        "id": "39ZWUtX6PtXo"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "slow_roads=df_active.filter(col(\"avg_speed_clean\")<25)\\\n",
        ".select(\"road_name\").distinct()\n",
        "\n",
        "busy_roads=df_active.filter(col(\"vehicle_count_clean\")>60)\\\n",
        ".select(\"road_name\").distinct()"
      ],
      "metadata": {
        "id": "0NMPlXGRQJQl"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "both=slow_roads.intersect(busy_roads)\n",
        "only_one=slow_roads.subtract(busy_roads)"
      ],
      "metadata": {
        "id": "UNrCrIVDQZBG"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PHASE 10 – Storage\n",
        "1. Write cleaned traffic data to:\n",
        "\n",
        "Parquet (partitioned by location)\n",
        "\n",
        "2. Write congestion analytics to:\n",
        "\n",
        "ORC\n",
        "\n",
        "3. Read back and validate."
      ],
      "metadata": {
        "id": "8wGBEe7XQrKZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_active.write\\\n",
        ".mode(\"overwrite\")\\\n",
        ".partitionBy(\"location\")\\\n",
        ".parquet(\"traffic_cleaned_parquet\")"
      ],
      "metadata": {
        "id": "UwgQHPCKQnbF"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "congested_roads.write\\\n",
        ".mode(\"overwrite\")\\\n",
        ".orc(\"congestion_analytics_orc\")"
      ],
      "metadata": {
        "id": "_E-iJCM4Q6QC"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.read.parquet(\"traffic_cleaned_parquet\").count()\n",
        "spark.read.orc(\"congestion_analytics_orc\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WaZr7swKQ_i2",
        "outputId": "67627928-45aa-43d6-b8b7-9d72b728f72b"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+------------------+\n",
            "|      road_name|         avg_speed|\n",
            "+---------------+------------------+\n",
            "|      EM Bypass|47.305273508964476|\n",
            "|      Link Road|  47.3713610932772|\n",
            "|  Whitefield Rd| 47.40783038021416|\n",
            "|        FC Road| 47.41019017359676|\n",
            "|      Howrah Rd| 47.41786602740956|\n",
            "|        MG Road| 47.42467508440872|\n",
            "|  University Rd| 47.42538415393851|\n",
            "|       Nagar Rd|47.429443229917716|\n",
            "|       GST Road| 47.44407903702021|\n",
            "|  Gachibowli Rd|47.455523521874355|\n",
            "|Eastern Express| 47.48790560471994|\n",
            "| Hitech City Rd| 47.51352853463453|\n",
            "|  Outer Ring Rd| 47.53179303464533|\n",
            "|            OMR|47.548242457791424|\n",
            "|      Ring Road| 47.55594236047568|\n",
            "|Western Express| 47.55637391185471|\n",
            "|    Park Street|47.579433971003745|\n",
            "|           NH48|47.613086790393126|\n",
            "|    Madhapur Rd| 47.64118452897408|\n",
            "|        Janpath| 47.67768541905838|\n",
            "+---------------+------------------+\n",
            "only showing top 20 rows\n"
          ]
        }
      ]
    }
  ]
}