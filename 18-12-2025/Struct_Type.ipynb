{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5E31EpHrls77"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "spark=SparkSession.builder.appName('Struct Type').getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data = [\n",
        "    (\"U001\",\"Abhishek\",28,\"Hyderabad\",50000),\n",
        "    (\"U002\",\"Neha\",32,\"Delhi\",62000),\n",
        "    (\"U003\",\"Ravi\",25,\"Bangalore\",45000),\n",
        "    (\"U004\",\"Pooja\",29,\"Mumbai\",58000)\n",
        "]"
      ],
      "metadata": {
        "id": "lrM4UMMmm5pn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import(\n",
        "    StructType,\n",
        "    StructField,\n",
        "    StringType,\n",
        "    IntegerType,\n",
        "    LongType\n",
        ")"
      ],
      "metadata": {
        "id": "r2_xBXYFnOzl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_schema=StructType([\n",
        "    StructField('user_id',StringType(),nullable=False),\n",
        "    StructField('name',StringType(),nullable=True),\n",
        "    StructField('age',IntegerType(),nullable=True),\n",
        "    StructField('city',StringType(),nullable=True),\n",
        "    StructField('salary',LongType(),nullable=True)\n",
        "])"
      ],
      "metadata": {
        "id": "uLL-nFORoJRs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_users=spark.createDataFrame(data=raw_data,schema=user_schema)\n",
        "df_users.show()\n",
        "df_users.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyCnuiPLpB7K",
        "outputId": "516cfc5f-1ecf-4bf0-f1e7-1c6a39bdabe2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------+---+---------+------+\n",
            "|user_id|    name|age|     city|salary|\n",
            "+-------+--------+---+---------+------+\n",
            "|   U001|Abhishek| 28|Hyderabad| 50000|\n",
            "|   U002|    Neha| 32|    Delhi| 62000|\n",
            "|   U003|    Ravi| 25|Bangalore| 45000|\n",
            "|   U004|   Pooja| 29|   Mumbai| 58000|\n",
            "+-------+--------+---+---------+------+\n",
            "\n",
            "root\n",
            " |-- user_id: string (nullable = false)\n",
            " |-- name: string (nullable = true)\n",
            " |-- age: integer (nullable = true)\n",
            " |-- city: string (nullable = true)\n",
            " |-- salary: long (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# wrong data\n",
        "raw_data2=[\n",
        "    (\"U005\",\"Amit\",\"Thirty\",\"Chennai\",40000)\n",
        "]\n",
        "df_users=spark.createDataFrame(data=raw_data2,schema=user_schema)\n",
        "df_users.show()"
      ],
      "metadata": {
        "id": "9LBnJlX0pS1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Array Type"
      ],
      "metadata": {
        "id": "TkSigOTuqwt5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import ArrayType"
      ],
      "metadata": {
        "id": "6jUuv62mplQv"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interest_data = [\n",
        "    (\"U001\",[\"AI\",\"ML\",\"Cloud\"]),\n",
        "    (\"U002\",[\"Testing\",\"Automation\"]),\n",
        "    (\"U003\",[\"Data Engineering\",\"Spark\",\"Kafka\"]),\n",
        "    (\"U004\",[\"UI/UX\"])\n",
        "]"
      ],
      "metadata": {
        "id": "KdPsc8gPq6jk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from IPython.utils.ipstruct import Struct\n",
        "interest_schema=StructType([\n",
        "    StructField('user_id',StringType(),nullable=False),\n",
        "    StructField('interests',ArrayType(StringType()),nullable=True)\n",
        "])"
      ],
      "metadata": {
        "id": "BxsHYC3Bq7RG"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_interests=spark.createDataFrame(data=interest_data,schema=interest_schema)\n",
        "df_interests.show(truncate=False)\n",
        "df_interests.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwFHWE1qrPxG",
        "outputId": "f0215b8e-4c1a-43c2-eae3-92a7b23d741b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------------------------------+\n",
            "|user_id|interests                       |\n",
            "+-------+--------------------------------+\n",
            "|U001   |[AI, ML, Cloud]                 |\n",
            "|U002   |[Testing, Automation]           |\n",
            "|U003   |[Data Engineering, Spark, Kafka]|\n",
            "|U004   |[UI/UX]                         |\n",
            "+-------+--------------------------------+\n",
            "\n",
            "root\n",
            " |-- user_id: string (nullable = false)\n",
            " |-- interests: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import explode\n",
        "df_interests.select(\"user_id\",explode(\"interests\").alias(\"interest\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssESCovqrazy",
        "outputId": "f620019c-d3ae-431f-963f-b1118aceb12c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------------+\n",
            "|user_id|        interest|\n",
            "+-------+----------------+\n",
            "|   U001|              AI|\n",
            "|   U001|              ML|\n",
            "|   U001|           Cloud|\n",
            "|   U002|         Testing|\n",
            "|   U002|      Automation|\n",
            "|   U003|Data Engineering|\n",
            "|   U003|           Spark|\n",
            "|   U003|           Kafka|\n",
            "|   U004|           UI/UX|\n",
            "+-------+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Map Type"
      ],
      "metadata": {
        "id": "em-yZ3lDsozs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import MapType"
      ],
      "metadata": {
        "id": "PTgiIjBysFsP"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device_data = [\n",
        "    (\"U001\",{\"mobile\":120,\"laptop\":300}),\n",
        "    (\"U002\",{\"tablet\":80}),\n",
        "    (\"U003\",{\"mobile\":200,\"desktop\":400}),\n",
        "    (\"U004\",{\"laptop\":250})\n",
        "]"
      ],
      "metadata": {
        "id": "TWtdTjOZsx8h"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device_schema=StructType([\n",
        "    StructField('user_id',StringType(),nullable=False),\n",
        "    StructField('device_usage',MapType(StringType(),IntegerType()),nullable=True)\n",
        "])"
      ],
      "metadata": {
        "id": "BfsfRYUws29C"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_devices=spark.createDataFrame(data=device_data,schema=device_schema)\n",
        "df_devices.show(truncate=False)\n",
        "df_devices.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fYMOcNztOqD",
        "outputId": "c076ce67-c09d-4f2e-b36b-6fe7703e4541"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------------------------------+\n",
            "|user_id|device_usage                   |\n",
            "+-------+-------------------------------+\n",
            "|U001   |{mobile -> 120, laptop -> 300} |\n",
            "|U002   |{tablet -> 80}                 |\n",
            "|U003   |{mobile -> 200, desktop -> 400}|\n",
            "|U004   |{laptop -> 250}                |\n",
            "+-------+-------------------------------+\n",
            "\n",
            "root\n",
            " |-- user_id: string (nullable = false)\n",
            " |-- device_usage: map (nullable = true)\n",
            " |    |-- key: string\n",
            " |    |-- value: integer (valueContainsNull = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nested_data = [\n",
        "    (\"U001\",(\"Hyderabad\",\"Telangana\",500081)),\n",
        "    (\"U002\",(\"Delhi\",\"Delhi\",110001)),\n",
        "    (\"U003\",(\"Bangalore\",\"Karnataka\",560001))\n",
        "]"
      ],
      "metadata": {
        "id": "j5flDT-jtTyw"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "address_schema=StructType([\n",
        "    StructField('city',StringType(),nullable=True),\n",
        "    StructField('state',StringType(),nullable=True),\n",
        "    StructField('pincode',IntegerType(),nullable=True)\n",
        "])\n",
        "\n",
        "profile_schema=StructType([\n",
        "    StructField('user_id',StringType(),nullable=False),\n",
        "    StructField('address',address_schema,nullable=True)\n",
        "])"
      ],
      "metadata": {
        "id": "0CuUfIjCuGo3"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_profiles=spark.createDataFrame(data=nested_data,schema=profile_schema)\n",
        "df_profiles.show(truncate=False)\n",
        "df_profiles.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PqvmvL4UvKqN",
        "outputId": "800e62f4-38ef-4d35-c676-ce1be5488ec2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------------------+\n",
            "|user_id|address                       |\n",
            "+-------+------------------------------+\n",
            "|U001   |{Hyderabad, Telangana, 500081}|\n",
            "|U002   |{Delhi, Delhi, 110001}        |\n",
            "|U003   |{Bangalore, Karnataka, 560001}|\n",
            "+-------+------------------------------+\n",
            "\n",
            "root\n",
            " |-- user_id: string (nullable = false)\n",
            " |-- address: struct (nullable = true)\n",
            " |    |-- city: string (nullable = true)\n",
            " |    |-- state: string (nullable = true)\n",
            " |    |-- pincode: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_profiles.select(\n",
        "    \"user_id\",\n",
        "    \"address.city\",\n",
        "    \"address.state\",\n",
        "    \"address.pincode\"\n",
        ").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVDeGzqavSGN",
        "outputId": "267ad6f9-c962-48bd-8ea2-a1e13a22a3f7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---------+---------+-------+\n",
            "|user_id|     city|    state|pincode|\n",
            "+-------+---------+---------+-------+\n",
            "|   U001|Hyderabad|Telangana| 500081|\n",
            "|   U002|    Delhi|    Delhi| 110001|\n",
            "|   U003|Bangalore|Karnataka| 560001|\n",
            "+-------+---------+---------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "df_users.withColumn(\n",
        "    \"salary_int\",\n",
        "    col(\"salary\").cast(\"int\")\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwmhB0hiv6sa",
        "outputId": "2af18195-295d-4a11-96c9-203e81ec1365"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[user_id: string, name: string, age: int, city: string, salary: bigint, salary_int: int]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    }
  ]
}