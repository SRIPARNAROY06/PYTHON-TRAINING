{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "E1aMyFeCF7C3"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "spark = SparkSession.builder \\\n",
        ".appName('Order Processing and Analytics Pipeline') \\\n",
        ".getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.window import Window"
      ],
      "metadata": {
        "id": "q4qeUG4vHWe2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PHASE 1 – Data Ingestion\n",
        "\n"
      ],
      "metadata": {
        "id": "ndWJNbhoKaHx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Load the CSV file without schema inference.\n"
      ],
      "metadata": {
        "id": "pmm-8TPgKggL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "orders_raw = spark.read \\\n",
        ".option(\"header\", \"true\") \\\n",
        ".option(\"inferSchema\", \"false\") \\\n",
        ".csv(\"orders.csv\")"
      ],
      "metadata": {
        "id": "VnXnqEIwJGnI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Print the schema.\n"
      ],
      "metadata": {
        "id": "IBJYBVcxKisa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "orders_raw.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y425RoimJmul",
        "outputId": "7e728e0a-b017-4751-e787-cbb6a8542836"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- order_id: string (nullable = true)\n",
            " |-- customer_id: string (nullable = true)\n",
            " |-- city: string (nullable = true)\n",
            " |-- category: string (nullable = true)\n",
            " |-- product: string (nullable = true)\n",
            " |-- amount: string (nullable = true)\n",
            " |-- order_date: string (nullable = true)\n",
            " |-- status: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Count total records.\n"
      ],
      "metadata": {
        "id": "k9361LlTKmKs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_records = orders_raw.count()\n",
        "print(\"Total records:\", total_records)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WeVgxdMgJ-EV",
        "outputId": "4975a5b8-e569-4048-da4b-3b35a104419e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total records: 300000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Show sample rows.\n"
      ],
      "metadata": {
        "id": "JU4gFsFbKpFd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "orders_raw.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVISxUdeKqwZ",
        "outputId": "6f29229f-529d-4ff4-946a-59dfb4ef7314"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+-----------+-----------+-----------+-------+----------+---------+\n",
            "|   order_id|customer_id|       city|   category|    product| amount|order_date|   status|\n",
            "+-----------+-----------+-----------+-----------+-----------+-------+----------+---------+\n",
            "|ORD00000000|    C000000| hyderabad |   grocery |       Oil |invalid|01/01/2024|Cancelled|\n",
            "|ORD00000001|    C000001|       Pune|    Grocery|      Sugar|  35430|2024-01-02|Completed|\n",
            "|ORD00000002|    C000002|       Pune|Electronics|     Mobile|  65358|2024-01-03|Completed|\n",
            "|ORD00000003|    C000003|  Bangalore|Electronics|     Laptop|   5558|2024-01-04|Completed|\n",
            "|ORD00000004|    C000004|       Pune|       Home|AirPurifier|  33659|2024-01-05|Completed|\n",
            "+-----------+-----------+-----------+-----------+-----------+-------+----------+---------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Explain why all columns must be treated as StringType initially."
      ],
      "metadata": {
        "id": "In4b56JHKrEP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load all columns as StringType initially when ingesting raw data (e.g., from CSVs).\n",
        "#Avoid schema inference issues that can cause incorrect data types or job failures.\n",
        "#Prevent data corruption by treating all values as strings during the first read.\n",
        "#Ensure complete data ingestion without loss, even if formats are inconsistent.\n",
        "#Enable controlled data processing: clean, validate, and cast columns explicitly later.\n",
        "#Improves reliability for pipelines handling messy or unpredictable raw data."
      ],
      "metadata": {
        "id": "3Z5bSmosKr8t"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PHASE 2 – Data Cleaning"
      ],
      "metadata": {
        "id": "kYupjsNGK5qU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Remove leading and trailing spaces from:\n",
        "city\n",
        "category\n",
        "product\n"
      ],
      "metadata": {
        "id": "XZANsj2JLQxT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "orders_trimmed = orders_raw\\\n",
        ".withColumn(\"city_clean\", trim(col(\"city\")))\\\n",
        ".withColumn(\"category_clean\", trim(col(\"category\")))\\\n",
        ".withColumn(\"product_clean\", trim(col(\"product\")))\n",
        "orders_trimmed.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EG5aGU28LSp7",
        "outputId": "40e53ff2-bcf9-4505-c0e8-693939b60c1f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+-----------+-----------+-----------+-------+----------+---------+----------+--------------+-------------+\n",
            "|   order_id|customer_id|       city|   category|    product| amount|order_date|   status|city_clean|category_clean|product_clean|\n",
            "+-----------+-----------+-----------+-----------+-----------+-------+----------+---------+----------+--------------+-------------+\n",
            "|ORD00000000|    C000000| hyderabad |   grocery |       Oil |invalid|01/01/2024|Cancelled| hyderabad|       grocery|          Oil|\n",
            "|ORD00000001|    C000001|       Pune|    Grocery|      Sugar|  35430|2024-01-02|Completed|      Pune|       Grocery|        Sugar|\n",
            "|ORD00000002|    C000002|       Pune|Electronics|     Mobile|  65358|2024-01-03|Completed|      Pune|   Electronics|       Mobile|\n",
            "|ORD00000003|    C000003|  Bangalore|Electronics|     Laptop|   5558|2024-01-04|Completed| Bangalore|   Electronics|       Laptop|\n",
            "|ORD00000004|    C000004|       Pune|       Home|AirPurifier|  33659|2024-01-05|Completed|      Pune|          Home|  AirPurifier|\n",
            "+-----------+-----------+-----------+-----------+-----------+-------+----------+---------+----------+--------------+-------------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Standardize text:\n",
        "Convert city, category, and product to proper case.\n"
      ],
      "metadata": {
        "id": "XdFsFZwiLTFj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "orders_text_std = orders_trimmed\\\n",
        ".withColumn(\"city_clean\", initcap(col(\"city_clean\")))\\\n",
        ".withColumn(\"category_clean\", initcap(col(\"category_clean\")))\\\n",
        ".withColumn(\"product_clean\", initcap(col(\"product_clean\")))\n",
        "orders_text_std.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6sdysR7LVNu",
        "outputId": "7f419f99-cc70-48b3-88dc-3128bab8a176"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+-----------+-----------+-----------+-------+----------+---------+----------+--------------+-------------+\n",
            "|   order_id|customer_id|       city|   category|    product| amount|order_date|   status|city_clean|category_clean|product_clean|\n",
            "+-----------+-----------+-----------+-----------+-----------+-------+----------+---------+----------+--------------+-------------+\n",
            "|ORD00000000|    C000000| hyderabad |   grocery |       Oil |invalid|01/01/2024|Cancelled| Hyderabad|       Grocery|          Oil|\n",
            "|ORD00000001|    C000001|       Pune|    Grocery|      Sugar|  35430|2024-01-02|Completed|      Pune|       Grocery|        Sugar|\n",
            "|ORD00000002|    C000002|       Pune|Electronics|     Mobile|  65358|2024-01-03|Completed|      Pune|   Electronics|       Mobile|\n",
            "|ORD00000003|    C000003|  Bangalore|Electronics|     Laptop|   5558|2024-01-04|Completed| Bangalore|   Electronics|       Laptop|\n",
            "|ORD00000004|    C000004|       Pune|       Home|AirPurifier|  33659|2024-01-05|Completed|      Pune|          Home|  Airpurifier|\n",
            "+-----------+-----------+-----------+-----------+-----------+-------+----------+---------+----------+--------------+-------------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Clean the amount column:\n",
        "Remove commas.\n",
        "Replace empty strings and invalid values with null.\n",
        "Convert amount into IntegerType.\n",
        "Rows with invalid amounts must not crash the pipeline.\n"
      ],
      "metadata": {
        "id": "2rk5pstbLVqc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "orders_amount_clean = orders_text_std\\\n",
        ".withColumn(\"amount_clean\", regexp_replace(col(\"amount\"), \",\", \"\"))\\\n",
        ".withColumn(\"amount_clean\",\n",
        "    when(col(\"amount_clean\").rlike(\"^[0-9]+$\"), col(\"amount_clean\").cast(IntegerType()))\\\n",
        "    .otherwise(None)\n",
        ")\n",
        "orders_amount_clean.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9NxMkSVLXjO",
        "outputId": "6536d21f-376f-4c3a-cc74-8562dc4a4306"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+-----------+-----------+-----------+-------+----------+---------+----------+--------------+-------------+------------+\n",
            "|   order_id|customer_id|       city|   category|    product| amount|order_date|   status|city_clean|category_clean|product_clean|amount_clean|\n",
            "+-----------+-----------+-----------+-----------+-----------+-------+----------+---------+----------+--------------+-------------+------------+\n",
            "|ORD00000000|    C000000| hyderabad |   grocery |       Oil |invalid|01/01/2024|Cancelled| Hyderabad|       Grocery|          Oil|        NULL|\n",
            "|ORD00000001|    C000001|       Pune|    Grocery|      Sugar|  35430|2024-01-02|Completed|      Pune|       Grocery|        Sugar|       35430|\n",
            "|ORD00000002|    C000002|       Pune|Electronics|     Mobile|  65358|2024-01-03|Completed|      Pune|   Electronics|       Mobile|       65358|\n",
            "|ORD00000003|    C000003|  Bangalore|Electronics|     Laptop|   5558|2024-01-04|Completed| Bangalore|   Electronics|       Laptop|        5558|\n",
            "|ORD00000004|    C000004|       Pune|       Home|AirPurifier|  33659|2024-01-05|Completed|      Pune|          Home|  Airpurifier|       33659|\n",
            "+-----------+-----------+-----------+-----------+-----------+-------+----------+---------+----------+--------------+-------------+------------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Clean the order_date column:\n",
        "\n",
        "Support the following formats:\n",
        "yyyy-MM-dd\n",
        "dd/MM/yyyy\n",
        "yyyy/MM/dd\n",
        "Create a new column:\n",
        "\n",
        "order_date_clean\n",
        "\n",
        "with DateType.\n"
      ],
      "metadata": {
        "id": "oFzAn2BALYBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "orders_date_clean = orders_amount_clean\\\n",
        ".withColumn(\n",
        "    \"order_date_clean\",\n",
        "    coalesce(\n",
        "    try_to_timestamp(col(\"order_date\"), lit(\"yyyy-MM-dd\")).cast(DateType()),\n",
        "    try_to_timestamp(col(\"order_date\"), lit(\"dd/MM/yyyy\")).cast(DateType()),\n",
        "    try_to_timestamp(col(\"order_date\"), lit(\"yyyy/MM/dd\")).cast(DateType())\n",
        "))\n",
        "orders_date_clean.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "veoWWMyYLanG",
        "outputId": "33fdfd16-2588-493e-9b04-95c872ff45c4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+-----------+-----------+-----------+-------+----------+---------+----------+--------------+-------------+------------+----------------+\n",
            "|   order_id|customer_id|       city|   category|    product| amount|order_date|   status|city_clean|category_clean|product_clean|amount_clean|order_date_clean|\n",
            "+-----------+-----------+-----------+-----------+-----------+-------+----------+---------+----------+--------------+-------------+------------+----------------+\n",
            "|ORD00000000|    C000000| hyderabad |   grocery |       Oil |invalid|01/01/2024|Cancelled| Hyderabad|       Grocery|          Oil|        NULL|      2024-01-01|\n",
            "|ORD00000001|    C000001|       Pune|    Grocery|      Sugar|  35430|2024-01-02|Completed|      Pune|       Grocery|        Sugar|       35430|      2024-01-02|\n",
            "|ORD00000002|    C000002|       Pune|Electronics|     Mobile|  65358|2024-01-03|Completed|      Pune|   Electronics|       Mobile|       65358|      2024-01-03|\n",
            "|ORD00000003|    C000003|  Bangalore|Electronics|     Laptop|   5558|2024-01-04|Completed| Bangalore|   Electronics|       Laptop|        5558|      2024-01-04|\n",
            "|ORD00000004|    C000004|       Pune|       Home|AirPurifier|  33659|2024-01-05|Completed|      Pune|          Home|  Airpurifier|       33659|      2024-01-05|\n",
            "+-----------+-----------+-----------+-----------+-----------+-------+----------+---------+----------+--------------+-------------+------------+----------------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. The original columns must remain for auditing."
      ],
      "metadata": {
        "id": "hcFG-z3dLbI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Schema of orders_date_clean (showing both original and cleaned columns):\")\n",
        "orders_date_clean.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4l3BTG8ULbyb",
        "outputId": "2e655744-9acd-42b0-da88-7728d2a2b3fe"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Schema of orders_date_clean (showing both original and cleaned columns):\n",
            "root\n",
            " |-- order_id: string (nullable = true)\n",
            " |-- customer_id: string (nullable = true)\n",
            " |-- city: string (nullable = true)\n",
            " |-- category: string (nullable = true)\n",
            " |-- product: string (nullable = true)\n",
            " |-- amount: string (nullable = true)\n",
            " |-- order_date: string (nullable = true)\n",
            " |-- status: string (nullable = true)\n",
            " |-- city_clean: string (nullable = true)\n",
            " |-- category_clean: string (nullable = true)\n",
            " |-- product_clean: string (nullable = true)\n",
            " |-- amount_clean: integer (nullable = true)\n",
            " |-- order_date_clean: date (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PHASE 3 – Data Validation\n"
      ],
      "metadata": {
        "id": "dONao386QdFI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Count how many records had invalid amounts.\n"
      ],
      "metadata": {
        "id": "wniLFERpQlbT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "invalid_amount_count = orders_date_clean.filter(col(\"amount_clean\").isNull()).count()\n",
        "print(\"Number of records with invalid amounts:\", invalid_amount_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgbSZfE8QnjT",
        "outputId": "d6ab0cd5-34c9-45ae-fed9-65c8a330ee9f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of records with invalid amounts: 25164\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Count how many records had invalid dates.\n"
      ],
      "metadata": {
        "id": "05zpRhmBQn7r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "invalid_date_count = orders_date_clean.filter(col(\"order_date_clean\").isNull()).count()\n",
        "print(\"Number of records with invalid dates: \", invalid_date_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jeJabD3aQpmS",
        "outputId": "77751763-a537-4814-8af8-9c36de70354c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of records with invalid dates:  2595\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Identify duplicate order_id values.\n"
      ],
      "metadata": {
        "id": "d36nsA6HQp92"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "duplicate_orders = orders_date_clean.groupBy(\"order_id\").count().filter(col(\"count\") > 1)\n",
        "duplicate_orders.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAdPVdRjQtOT",
        "outputId": "87a4232b-ebaa-441d-e222-463b1bb13927"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----+\n",
            "|order_id|count|\n",
            "+--------+-----+\n",
            "+--------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Remove duplicates using order_id.\n"
      ],
      "metadata": {
        "id": "8JcQwdJvQtmU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "orders_deduped = orders_date_clean.dropDuplicates([\"order_id\"])\n",
        "orders_deduped.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfCEheY7QwGg",
        "outputId": "70adeb72-58d3-40ee-ea36-a914b03bc811"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+---------+-----------+-------+------+----------+---------+----------+--------------+-------------+------------+----------------+\n",
            "|   order_id|customer_id|     city|   category|product|amount|order_date|   status|city_clean|category_clean|product_clean|amount_clean|order_date_clean|\n",
            "+-----------+-----------+---------+-----------+-------+------+----------+---------+----------+--------------+-------------+------------+----------------+\n",
            "|ORD00000001|    C000001|     Pune|    Grocery|  Sugar| 35430|2024-01-02|Completed|      Pune|       Grocery|        Sugar|       35430|      2024-01-02|\n",
            "|ORD00000007|    C000007|     Pune|    Grocery|   Rice| 45362|2024-01-08|Completed|      Pune|       Grocery|         Rice|       45362|      2024-01-08|\n",
            "|ORD00000008|    C000008|Bangalore|    Fashion|  Jeans| 10563|2024-01-09|Completed| Bangalore|       Fashion|        Jeans|       10563|      2024-01-09|\n",
            "|ORD00000010|    C000010|Bangalore|    Grocery|  Sugar| 66576|2024-01-11|Completed| Bangalore|       Grocery|        Sugar|       66576|      2024-01-11|\n",
            "|ORD00000011|    C000011|  Kolkata|Electronics| Tablet| 50318|12/01/2024|Completed|   Kolkata|   Electronics|       Tablet|       50318|      2024-01-12|\n",
            "+-----------+-----------+---------+-----------+-------+------+----------+---------+----------+--------------+-------------+------------+----------------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Filter only records with:\n",
        "\n",
        "status = \"Completed\"\n",
        "\n"
      ],
      "metadata": {
        "id": "Ga87VaQ2QwcZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "orders_completed = orders_deduped.filter(col(\"status\") == \"Completed\")\n",
        "orders_completed.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7K-ce1UYQyWc",
        "outputId": "61e2cc60-0173-4193-92c1-cc45d6871582"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+---------+-----------+-------+------+----------+---------+----------+--------------+-------------+------------+----------------+\n",
            "|   order_id|customer_id|     city|   category|product|amount|order_date|   status|city_clean|category_clean|product_clean|amount_clean|order_date_clean|\n",
            "+-----------+-----------+---------+-----------+-------+------+----------+---------+----------+--------------+-------------+------------+----------------+\n",
            "|ORD00000001|    C000001|     Pune|    Grocery|  Sugar| 35430|2024-01-02|Completed|      Pune|       Grocery|        Sugar|       35430|      2024-01-02|\n",
            "|ORD00000007|    C000007|     Pune|    Grocery|   Rice| 45362|2024-01-08|Completed|      Pune|       Grocery|         Rice|       45362|      2024-01-08|\n",
            "|ORD00000008|    C000008|Bangalore|    Fashion|  Jeans| 10563|2024-01-09|Completed| Bangalore|       Fashion|        Jeans|       10563|      2024-01-09|\n",
            "|ORD00000010|    C000010|Bangalore|    Grocery|  Sugar| 66576|2024-01-11|Completed| Bangalore|       Grocery|        Sugar|       66576|      2024-01-11|\n",
            "|ORD00000011|    C000011|  Kolkata|Electronics| Tablet| 50318|12/01/2024|Completed|   Kolkata|   Electronics|       Tablet|       50318|      2024-01-12|\n",
            "+-----------+-----------+---------+-----------+-------+------+----------+---------+----------+--------------+-------------+------------+----------------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Record row counts at every stage."
      ],
      "metadata": {
        "id": "wQxlBNRrQyu8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"initial\", total_records)\n",
        "print(\"after dedup\", orders_deduped.count())\n",
        "print(\"after filtering\", orders_completed.count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCOlin1FQzti",
        "outputId": "5da0f1e5-9c51-421d-834e-1350fc6e96ca"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initial 300000\n",
            "after dedup 300000\n",
            "after filtering 285000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PHASE 4 – Performance Engineering\n"
      ],
      "metadata": {
        "id": "jNnK2h0zRvBg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Check the number of partitions.\n"
      ],
      "metadata": {
        "id": "xHoFEdWhRzas"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "orders_completed.rdd.getNumPartitions()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gN1Jt77jRsHC",
        "outputId": "7a934480-6d6a-49ab-e394-414eb0932fd0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Run a groupBy on city and calculate total revenue.\n"
      ],
      "metadata": {
        "id": "-hvyUjOoR1na"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "city_revenue = orders_completed.groupBy(\"city_clean\").agg(sum(\"amount_clean\").alias(\"total_revenue\"))\n",
        "city_revenue.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zv7nU8d4R3cA",
        "outputId": "7233fa0d-69a9-460f-94dc-cf7902c97abc"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------------+\n",
            "|city_clean|total_revenue|\n",
            "+----------+-------------+\n",
            "| Bangalore|   1628527093|\n",
            "|   Chennai|   1629865247|\n",
            "|    Mumbai|   1625518096|\n",
            "|   Kolkata|   1624300497|\n",
            "|      Pune|   1646196535|\n",
            "+----------+-------------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Use:\n",
        "\n",
        "explain(True)\n",
        "\n",
        "to analyze execution.\n"
      ],
      "metadata": {
        "id": "CTTHXCWPR4K8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "city_revenue.explain(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSeAA93jR56O",
        "outputId": "177684ed-e120-4151-c3b3-23fb3c41bd0c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Parsed Logical Plan ==\n",
            "'Aggregate ['city_clean], ['city_clean, 'sum('amount_clean) AS total_revenue#1004]\n",
            "+- Filter (status#24 = Completed)\n",
            "   +- Deduplicate [order_id#17]\n",
            "      +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#116, category_clean#117, product_clean#118, amount_clean#162, coalesce(cast(try_to_timestamp(order_date#23, Some(yyyy-MM-dd), TimestampType, Some(Etc/UTC), false) as date), cast(try_to_timestamp(order_date#23, Some(dd/MM/yyyy), TimestampType, Some(Etc/UTC), false) as date), cast(try_to_timestamp(order_date#23, Some(yyyy/MM/dd), TimestampType, Some(Etc/UTC), false) as date)) AS order_date_clean#315]\n",
            "         +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#116, category_clean#117, product_clean#118, CASE WHEN RLIKE(amount_clean#161, ^[0-9]+$) THEN cast(amount_clean#161 as int) ELSE cast(null as int) END AS amount_clean#162]\n",
            "            +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#116, category_clean#117, product_clean#118, regexp_replace(amount#22, ,, , 1) AS amount_clean#161]\n",
            "               +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#116, category_clean#117, initcap(product_clean#73) AS product_clean#118]\n",
            "                  +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#116, initcap(category_clean#72) AS category_clean#117, product_clean#73]\n",
            "                     +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, initcap(city_clean#71) AS city_clean#116, category_clean#72, product_clean#73]\n",
            "                        +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, category_clean#72, trim(product#21, None) AS product_clean#73]\n",
            "                           +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, trim(category#20, None) AS category_clean#72]\n",
            "                              +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, trim(city#19, None) AS city_clean#71]\n",
            "                                 +- Relation [order_id#17,customer_id#18,city#19,category#20,product#21,amount#22,order_date#23,status#24] csv\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "city_clean: string, total_revenue: bigint\n",
            "Aggregate [city_clean#116], [city_clean#116, sum(amount_clean#162) AS total_revenue#1004L]\n",
            "+- Filter (status#24 = Completed)\n",
            "   +- Deduplicate [order_id#17]\n",
            "      +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#116, category_clean#117, product_clean#118, amount_clean#162, coalesce(cast(try_to_timestamp(order_date#23, Some(yyyy-MM-dd), TimestampType, Some(Etc/UTC), false) as date), cast(try_to_timestamp(order_date#23, Some(dd/MM/yyyy), TimestampType, Some(Etc/UTC), false) as date), cast(try_to_timestamp(order_date#23, Some(yyyy/MM/dd), TimestampType, Some(Etc/UTC), false) as date)) AS order_date_clean#315]\n",
            "         +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#116, category_clean#117, product_clean#118, CASE WHEN RLIKE(amount_clean#161, ^[0-9]+$) THEN cast(amount_clean#161 as int) ELSE cast(null as int) END AS amount_clean#162]\n",
            "            +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#116, category_clean#117, product_clean#118, regexp_replace(amount#22, ,, , 1) AS amount_clean#161]\n",
            "               +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#116, category_clean#117, initcap(product_clean#73) AS product_clean#118]\n",
            "                  +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#116, initcap(category_clean#72) AS category_clean#117, product_clean#73]\n",
            "                     +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, initcap(city_clean#71) AS city_clean#116, category_clean#72, product_clean#73]\n",
            "                        +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, category_clean#72, trim(product#21, None) AS product_clean#73]\n",
            "                           +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, trim(category#20, None) AS category_clean#72]\n",
            "                              +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, trim(city#19, None) AS city_clean#71]\n",
            "                                 +- Relation [order_id#17,customer_id#18,city#19,category#20,product#21,amount#22,order_date#23,status#24] csv\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Aggregate [city_clean#1110], [city_clean#1110, sum(amount_clean#1116) AS total_revenue#1004L]\n",
            "+- Project [city_clean#1110, amount_clean#1116]\n",
            "   +- Filter (isnotnull(status#1108) AND (status#1108 = Completed))\n",
            "      +- Aggregate [order_id#17], [first(status#24, false) AS status#1108, first(city_clean#116, false) AS city_clean#1110, first(amount_clean#162, false) AS amount_clean#1116]\n",
            "         +- Project [order_id#17, status#24, city_clean#116, CASE WHEN RLIKE(amount_clean#161, ^[0-9]+$) THEN cast(amount_clean#161 as int) END AS amount_clean#162]\n",
            "            +- Project [order_id#17, status#24, initcap(trim(city#19, None)) AS city_clean#116, regexp_replace(amount#22, ,, , 1) AS amount_clean#161]\n",
            "               +- Relation [order_id#17,customer_id#18,city#19,category#20,product#21,amount#22,order_date#23,status#24] csv\n",
            "\n",
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- HashAggregate(keys=[city_clean#1110], functions=[sum(amount_clean#1116)], output=[city_clean#1110, total_revenue#1004L])\n",
            "   +- Exchange hashpartitioning(city_clean#1110, 200), ENSURE_REQUIREMENTS, [plan_id=1053]\n",
            "      +- HashAggregate(keys=[city_clean#1110], functions=[partial_sum(amount_clean#1116)], output=[city_clean#1110, sum#1120L])\n",
            "         +- Project [city_clean#1110, amount_clean#1116]\n",
            "            +- Filter (isnotnull(status#1108) AND (status#1108 = Completed))\n",
            "               +- SortAggregate(key=[order_id#17], functions=[first(status#24, false), first(city_clean#116, false), first(amount_clean#162, false)], output=[status#1108, city_clean#1110, amount_clean#1116])\n",
            "                  +- Sort [order_id#17 ASC NULLS FIRST], false, 0\n",
            "                     +- Exchange hashpartitioning(order_id#17, 200), ENSURE_REQUIREMENTS, [plan_id=1046]\n",
            "                        +- SortAggregate(key=[order_id#17], functions=[partial_first(status#24, false), partial_first(city_clean#116, false), partial_first(amount_clean#162, false)], output=[order_id#17, first#1127, valueSet#1128, first#1129, valueSet#1130, first#1131, valueSet#1132])\n",
            "                           +- Sort [order_id#17 ASC NULLS FIRST], false, 0\n",
            "                              +- Project [order_id#17, status#24, city_clean#116, CASE WHEN RLIKE(amount_clean#161, ^[0-9]+$) THEN cast(amount_clean#161 as int) END AS amount_clean#162]\n",
            "                                 +- Project [order_id#17, status#24, initcap(trim(city#19, None)) AS city_clean#116, regexp_replace(amount#22, ,, , 1) AS amount_clean#161]\n",
            "                                    +- FileScan csv [order_id#17,city#19,amount#22,status#24] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/content/orders.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<order_id:string,city:string,amount:string,status:string>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Identify where shuffle happens.\n"
      ],
      "metadata": {
        "id": "V4LY9dweR6RX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#By examining the \"Physical Plan\" section of the city_revenue.explain(True) output, we can identify the shuffle operations. Shuffles are indicated by Exchange operators.\n",
        "\n",
        "#In this particular plan, shuffles happen at these stages:\n",
        "\n",
        "#After the initial data read and projection: There's an Exchange hashpartitioning(order_id#17, 200) before the SortAggregate for deduplication. This shuffles the data by order_id to ensure all records for a given order_id are on the same partition for accurate deduplication.\n",
        "#Before the final aggregation: There's another Exchange hashpartitioning(city_clean#1110, 200) before the final HashAggregate that calculates the total revenue per city. This shuffles the data by city_clean to bring all records belonging to the same city together on a single partition for efficient aggregation.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pBMLY2jR70Q",
        "outputId": "e31f5b8d-b334-426c-8132-fd80461bfe97"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Repartition the dataset by city.\n"
      ],
      "metadata": {
        "id": "347E8HrbR8Qm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "orders_repartitioned = orders_completed.repartition(\"city_clean\")\n",
        "orders_repartitioned.rdd.getNumPartitions()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yVug-ujR92n",
        "outputId": "37c2c9c3-dc6d-4ce6-aaf7-fd057221c4ec"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Compare execution plans before and after repartition.\n",
        "This phase exists to demonstrate understanding of Spark internals, not just outputs."
      ],
      "metadata": {
        "id": "72OKtIBSR-LF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "orders_completed.groupBy(\"city_clean\").agg(sum(\"amount_clean\").alias(\"total_revenue\")).explain(True)\n",
        "orders_repartitioned.groupBy(\"city_clean\").agg(sum(\"amount_clean\").alias(\"total_revenue\")).explain(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjjSF4P2SDtV",
        "outputId": "91182afa-2f5a-4f1c-c357-0933446e736d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Parsed Logical Plan ==\n",
            "'Aggregate ['city_clean], ['city_clean, 'sum('amount_clean) AS total_revenue#1485]\n",
            "+- Filter (status#24 = Completed)\n",
            "   +- Deduplicate [order_id#17]\n",
            "      +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#116, category_clean#117, product_clean#118, amount_clean#162, coalesce(cast(try_to_timestamp(order_date#23, Some(yyyy-MM-dd), TimestampType, Some(Etc/UTC), false) as date), cast(try_to_timestamp(order_date#23, Some(dd/MM/yyyy), TimestampType, Some(Etc/UTC), false) as date), cast(try_to_timestamp(order_date#23, Some(yyyy/MM/dd), TimestampType, Some(Etc/UTC), false) as date)) AS order_date_clean#315]\n",
            "         +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#116, category_clean#117, product_clean#118, CASE WHEN RLIKE(amount_clean#161, ^[0-9]+$) THEN cast(amount_clean#161 as int) ELSE cast(null as int) END AS amount_clean#162]\n",
            "            +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#116, category_clean#117, product_clean#118, regexp_replace(amount#22, ,, , 1) AS amount_clean#161]\n",
            "               +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#116, category_clean#117, initcap(product_clean#73) AS product_clean#118]\n",
            "                  +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#116, initcap(category_clean#72) AS category_clean#117, product_clean#73]\n",
            "                     +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, initcap(city_clean#71) AS city_clean#116, category_clean#72, product_clean#73]\n",
            "                        +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, category_clean#72, trim(product#21, None) AS product_clean#73]\n",
            "                           +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, trim(category#20, None) AS category_clean#72]\n",
            "                              +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, trim(city#19, None) AS city_clean#71]\n",
            "                                 +- Relation [order_id#17,customer_id#18,city#19,category#20,product#21,amount#22,order_date#23,status#24] csv\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "city_clean: string, total_revenue: bigint\n",
            "Aggregate [city_clean#116], [city_clean#116, sum(amount_clean#162) AS total_revenue#1485L]\n",
            "+- Filter (status#24 = Completed)\n",
            "   +- Deduplicate [order_id#17]\n",
            "      +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#116, category_clean#117, product_clean#118, amount_clean#162, coalesce(cast(try_to_timestamp(order_date#23, Some(yyyy-MM-dd), TimestampType, Some(Etc/UTC), false) as date), cast(try_to_timestamp(order_date#23, Some(dd/MM/yyyy), TimestampType, Some(Etc/UTC), false) as date), cast(try_to_timestamp(order_date#23, Some(yyyy/MM/dd), TimestampType, Some(Etc/UTC), false) as date)) AS order_date_clean#315]\n",
            "         +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#116, category_clean#117, product_clean#118, CASE WHEN RLIKE(amount_clean#161, ^[0-9]+$) THEN cast(amount_clean#161 as int) ELSE cast(null as int) END AS amount_clean#162]\n",
            "            +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#116, category_clean#117, product_clean#118, regexp_replace(amount#22, ,, , 1) AS amount_clean#161]\n",
            "               +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#116, category_clean#117, initcap(product_clean#73) AS product_clean#118]\n",
            "                  +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#116, initcap(category_clean#72) AS category_clean#117, product_clean#73]\n",
            "                     +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, initcap(city_clean#71) AS city_clean#116, category_clean#72, product_clean#73]\n",
            "                        +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, category_clean#72, trim(product#21, None) AS product_clean#73]\n",
            "                           +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, trim(category#20, None) AS category_clean#72]\n",
            "                              +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, trim(city#19, None) AS city_clean#71]\n",
            "                                 +- Relation [order_id#17,customer_id#18,city#19,category#20,product#21,amount#22,order_date#23,status#24] csv\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Aggregate [city_clean#1515], [city_clean#1515, sum(amount_clean#1521) AS total_revenue#1485L]\n",
            "+- Project [city_clean#1515, amount_clean#1521]\n",
            "   +- Filter (isnotnull(status#1513) AND (status#1513 = Completed))\n",
            "      +- Aggregate [order_id#17], [first(status#24, false) AS status#1513, first(city_clean#116, false) AS city_clean#1515, first(amount_clean#162, false) AS amount_clean#1521]\n",
            "         +- Project [order_id#17, status#24, city_clean#116, CASE WHEN RLIKE(amount_clean#161, ^[0-9]+$) THEN cast(amount_clean#161 as int) END AS amount_clean#162]\n",
            "            +- Project [order_id#17, status#24, initcap(trim(city#19, None)) AS city_clean#116, regexp_replace(amount#22, ,, , 1) AS amount_clean#161]\n",
            "               +- Relation [order_id#17,customer_id#18,city#19,category#20,product#21,amount#22,order_date#23,status#24] csv\n",
            "\n",
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- HashAggregate(keys=[city_clean#1515], functions=[sum(amount_clean#1521)], output=[city_clean#1515, total_revenue#1485L])\n",
            "   +- Exchange hashpartitioning(city_clean#1515, 200), ENSURE_REQUIREMENTS, [plan_id=1339]\n",
            "      +- HashAggregate(keys=[city_clean#1515], functions=[partial_sum(amount_clean#1521)], output=[city_clean#1515, sum#1525L])\n",
            "         +- Project [city_clean#1515, amount_clean#1521]\n",
            "            +- Filter (isnotnull(status#1513) AND (status#1513 = Completed))\n",
            "               +- SortAggregate(key=[order_id#17], functions=[first(status#24, false), first(city_clean#116, false), first(amount_clean#162, false)], output=[status#1513, city_clean#1515, amount_clean#1521])\n",
            "                  +- Sort [order_id#17 ASC NULLS FIRST], false, 0\n",
            "                     +- Exchange hashpartitioning(order_id#17, 200), ENSURE_REQUIREMENTS, [plan_id=1332]\n",
            "                        +- SortAggregate(key=[order_id#17], functions=[partial_first(status#24, false), partial_first(city_clean#116, false), partial_first(amount_clean#162, false)], output=[order_id#17, first#1532, valueSet#1533, first#1534, valueSet#1535, first#1536, valueSet#1537])\n",
            "                           +- Sort [order_id#17 ASC NULLS FIRST], false, 0\n",
            "                              +- Project [order_id#17, status#24, city_clean#116, CASE WHEN RLIKE(amount_clean#161, ^[0-9]+$) THEN cast(amount_clean#161 as int) END AS amount_clean#162]\n",
            "                                 +- Project [order_id#17, status#24, initcap(trim(city#19, None)) AS city_clean#116, regexp_replace(amount#22, ,, , 1) AS amount_clean#161]\n",
            "                                    +- FileScan csv [order_id#17,city#19,amount#22,status#24] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/content/orders.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<order_id:string,city:string,amount:string,status:string>\n",
            "\n",
            "== Parsed Logical Plan ==\n",
            "'Aggregate ['city_clean], ['city_clean, 'sum('amount_clean) AS total_revenue#1538]\n",
            "+- RepartitionByExpression [city_clean#116]\n",
            "   +- Filter (status#24 = Completed)\n",
            "      +- Deduplicate [order_id#17]\n",
            "         +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#116, category_clean#117, product_clean#118, amount_clean#162, coalesce(cast(try_to_timestamp(order_date#23, Some(yyyy-MM-dd), TimestampType, Some(Etc/UTC), false) as date), cast(try_to_timestamp(order_date#23, Some(dd/MM/yyyy), TimestampType, Some(Etc/UTC), false) as date), cast(try_to_timestamp(order_date#23, Some(yyyy/MM/dd), TimestampType, Some(Etc/UTC), false) as date)) AS order_date_clean#315]\n",
            "            +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#116, category_clean#117, product_clean#118, CASE WHEN RLIKE(amount_clean#161, ^[0-9]+$) THEN cast(amount_clean#161 as int) ELSE cast(null as int) END AS amount_clean#162]\n",
            "               +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#116, category_clean#117, product_clean#118, regexp_replace(amount#22, ,, , 1) AS amount_clean#161]\n",
            "                  +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#116, category_clean#117, initcap(product_clean#73) AS product_clean#118]\n",
            "                     +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#116, initcap(category_clean#72) AS category_clean#117, product_clean#73]\n",
            "                        +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, initcap(city_clean#71) AS city_clean#116, category_clean#72, product_clean#73]\n",
            "                           +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, category_clean#72, trim(product#21, None) AS product_clean#73]\n",
            "                              +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, trim(category#20, None) AS category_clean#72]\n",
            "                                 +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, trim(city#19, None) AS city_clean#71]\n",
            "                                    +- Relation [order_id#17,customer_id#18,city#19,category#20,product#21,amount#22,order_date#23,status#24] csv\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "city_clean: string, total_revenue: bigint\n",
            "Aggregate [city_clean#116], [city_clean#116, sum(amount_clean#162) AS total_revenue#1538L]\n",
            "+- RepartitionByExpression [city_clean#116]\n",
            "   +- Filter (status#24 = Completed)\n",
            "      +- Deduplicate [order_id#17]\n",
            "         +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#116, category_clean#117, product_clean#118, amount_clean#162, coalesce(cast(try_to_timestamp(order_date#23, Some(yyyy-MM-dd), TimestampType, Some(Etc/UTC), false) as date), cast(try_to_timestamp(order_date#23, Some(dd/MM/yyyy), TimestampType, Some(Etc/UTC), false) as date), cast(try_to_timestamp(order_date#23, Some(yyyy/MM/dd), TimestampType, Some(Etc/UTC), false) as date)) AS order_date_clean#315]\n",
            "            +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#116, category_clean#117, product_clean#118, CASE WHEN RLIKE(amount_clean#161, ^[0-9]+$) THEN cast(amount_clean#161 as int) ELSE cast(null as int) END AS amount_clean#162]\n",
            "               +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#116, category_clean#117, product_clean#118, regexp_replace(amount#22, ,, , 1) AS amount_clean#161]\n",
            "                  +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#116, category_clean#117, initcap(product_clean#73) AS product_clean#118]\n",
            "                     +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#116, initcap(category_clean#72) AS category_clean#117, product_clean#73]\n",
            "                        +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, initcap(city_clean#71) AS city_clean#116, category_clean#72, product_clean#73]\n",
            "                           +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, category_clean#72, trim(product#21, None) AS product_clean#73]\n",
            "                              +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, trim(category#20, None) AS category_clean#72]\n",
            "                                 +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, trim(city#19, None) AS city_clean#71]\n",
            "                                    +- Relation [order_id#17,customer_id#18,city#19,category#20,product#21,amount#22,order_date#23,status#24] csv\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Aggregate [city_clean#1568], [city_clean#1568, sum(amount_clean#1574) AS total_revenue#1538L]\n",
            "+- RepartitionByExpression [city_clean#1568]\n",
            "   +- Project [city_clean#1568, amount_clean#1574]\n",
            "      +- Filter (isnotnull(status#1566) AND (status#1566 = Completed))\n",
            "         +- Aggregate [order_id#17], [first(status#24, false) AS status#1566, first(city_clean#116, false) AS city_clean#1568, first(amount_clean#162, false) AS amount_clean#1574]\n",
            "            +- Project [order_id#17, status#24, city_clean#116, CASE WHEN RLIKE(amount_clean#161, ^[0-9]+$) THEN cast(amount_clean#161 as int) END AS amount_clean#162]\n",
            "               +- Project [order_id#17, status#24, initcap(trim(city#19, None)) AS city_clean#116, regexp_replace(amount#22, ,, , 1) AS amount_clean#161]\n",
            "                  +- Relation [order_id#17,customer_id#18,city#19,category#20,product#21,amount#22,order_date#23,status#24] csv\n",
            "\n",
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- HashAggregate(keys=[city_clean#1568], functions=[sum(amount_clean#1574)], output=[city_clean#1568, total_revenue#1538L])\n",
            "   +- HashAggregate(keys=[city_clean#1568], functions=[partial_sum(amount_clean#1574)], output=[city_clean#1568, sum#1578L])\n",
            "      +- Exchange hashpartitioning(city_clean#1568, 200), REPARTITION_BY_COL, [plan_id=1385]\n",
            "         +- Project [city_clean#1568, amount_clean#1574]\n",
            "            +- Filter (isnotnull(status#1566) AND (status#1566 = Completed))\n",
            "               +- SortAggregate(key=[order_id#17], functions=[first(status#24, false), first(city_clean#116, false), first(amount_clean#162, false)], output=[status#1566, city_clean#1568, amount_clean#1574])\n",
            "                  +- Sort [order_id#17 ASC NULLS FIRST], false, 0\n",
            "                     +- Exchange hashpartitioning(order_id#17, 200), ENSURE_REQUIREMENTS, [plan_id=1380]\n",
            "                        +- SortAggregate(key=[order_id#17], functions=[partial_first(status#24, false), partial_first(city_clean#116, false), partial_first(amount_clean#162, false)], output=[order_id#17, first#1585, valueSet#1586, first#1587, valueSet#1588, first#1589, valueSet#1590])\n",
            "                           +- Sort [order_id#17 ASC NULLS FIRST], false, 0\n",
            "                              +- Project [order_id#17, status#24, city_clean#116, CASE WHEN RLIKE(amount_clean#161, ^[0-9]+$) THEN cast(amount_clean#161 as int) END AS amount_clean#162]\n",
            "                                 +- Project [order_id#17, status#24, initcap(trim(city#19, None)) AS city_clean#116, regexp_replace(amount#22, ,, , 1) AS amount_clean#161]\n",
            "                                    +- FileScan csv [order_id#17,city#19,amount#22,status#24] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/content/orders.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<order_id:string,city:string,amount:string,status:string>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PHASE 5 – Analytics"
      ],
      "metadata": {
        "id": "zQoMFzqRTQ9m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Total revenue per city.\n"
      ],
      "metadata": {
        "id": "Z51TIaBwTYRQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "orders_completed.groupBy(\"city_clean\").agg(sum(\"amount_clean\").alias(\"total_revenue\")).show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7QBzuuQTOOH",
        "outputId": "ff76e7ea-f907-4d1c-ee08-59d03e6456ce"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------------+\n",
            "|city_clean|total_revenue|\n",
            "+----------+-------------+\n",
            "| Bangalore|   1628527093|\n",
            "|   Chennai|   1629865247|\n",
            "|    Mumbai|   1625518096|\n",
            "|   Kolkata|   1624300497|\n",
            "|      Pune|   1646196535|\n",
            "+----------+-------------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Total revenue per category.\n"
      ],
      "metadata": {
        "id": "W9xo8S3iTaOJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "orders_completed.groupBy(\"category_clean\").agg(sum(\"amount_clean\").alias(\"total_revenue\")).show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwtYwN1HTcLj",
        "outputId": "f11671ae-541e-4ef5-861a-4fcece8f8a6d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+-------------+\n",
            "|category_clean|total_revenue|\n",
            "+--------------+-------------+\n",
            "|          Home|   2868467576|\n",
            "|       Fashion|   2834182172|\n",
            "|       Grocery|   2866272106|\n",
            "|   Electronics|   2867568870|\n",
            "+--------------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Average order value per city.\n"
      ],
      "metadata": {
        "id": "884kEYZCTcgY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "orders_completed.groupBy(\"city_clean\").agg(avg(\"amount_clean\").alias(\"avg_order_value\")).show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKIqfZMKTeHp",
        "outputId": "d6887b17-796f-4392-e818-5eb2d44261b8"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------------------+\n",
            "|city_clean|   avg_order_value|\n",
            "+----------+------------------+\n",
            "| Bangalore|44098.867908689645|\n",
            "|   Chennai| 43628.27900315863|\n",
            "|    Mumbai| 43723.75651612556|\n",
            "|   Kolkata|43709.816662630175|\n",
            "|      Pune|43930.204013556424|\n",
            "+----------+------------------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Top 10 products by revenue.\n"
      ],
      "metadata": {
        "id": "eGUza8yWTebI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "orders_completed.groupBy(\"product_clean\").agg(sum(\"amount_clean\").alias(\"total_revenue\")).orderBy(col(\"total_revenue\").desc()).limit(10).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-aHdEMUThHo",
        "outputId": "c2097f14-fad4-472a-f284-84598cbc6967"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+-------------+\n",
            "|product_clean|total_revenue|\n",
            "+-------------+-------------+\n",
            "|          Oil|    963572869|\n",
            "|       Laptop|    962496295|\n",
            "|       Tablet|    960719999|\n",
            "|       Vacuum|    959149427|\n",
            "|        Mixer|    957140026|\n",
            "|         Rice|    954494237|\n",
            "|  Airpurifier|    952178123|\n",
            "|        Jeans|    951286127|\n",
            "|        Sugar|    948205000|\n",
            "|        Shoes|    946799102|\n",
            "+-------------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Cities sorted by revenue descending."
      ],
      "metadata": {
        "id": "V4A_DSOMThhk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "city_revenue.orderBy(col(\"total_revenue\").desc()).show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuqPMHybTio4",
        "outputId": "fe5016d2-fec1-4300-b13c-9d3413b33af1"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------------+\n",
            "|city_clean|total_revenue|\n",
            "+----------+-------------+\n",
            "|      Pune|   1646196535|\n",
            "| Hyderabad|   1642443340|\n",
            "|     Delhi|   1639639916|\n",
            "|   Chennai|   1629865247|\n",
            "| Bangalore|   1628527093|\n",
            "+----------+-------------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PHASE 6 – Window Functions\n"
      ],
      "metadata": {
        "id": "zUOPLX9AUhuJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Rank cities by revenue.\n"
      ],
      "metadata": {
        "id": "OytfOFkWUkuS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "city_rank_window = Window.orderBy(col(\"total_revenue\").desc())\n",
        "city_ranked = city_revenue.withColumn(\"rank\", row_number().over(city_rank_window))\n",
        "city_ranked.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsRsnutSUda0",
        "outputId": "247c7229-6707-4766-c690-f3e2395e8c93"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------------+----+\n",
            "|city_clean|total_revenue|rank|\n",
            "+----------+-------------+----+\n",
            "|      Pune|   1646196535|   1|\n",
            "| Hyderabad|   1642443340|   2|\n",
            "|     Delhi|   1639639916|   3|\n",
            "|   Chennai|   1629865247|   4|\n",
            "| Bangalore|   1628527093|   5|\n",
            "+----------+-------------+----+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Rank products inside each category by revenue.\n"
      ],
      "metadata": {
        "id": "BZzne6S1Umnw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "category_product_rank_window = Window.partitionBy(\"category_clean\").orderBy(col(\"total_revenue\").desc())"
      ],
      "metadata": {
        "id": "Nfn-z-6SUoh6"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Find the top product for every category.\n"
      ],
      "metadata": {
        "id": "vzpXeUOEUo8C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "product_revenue = orders_completed.groupBy(\"category_clean\", \"product_clean\").agg(sum(\"amount_clean\").alias(\"total_revenue\"))\n",
        "top_products = product_revenue.withColumn(\"rank\", row_number().over(category_product_rank_window)).filter(col(\"rank\") == 1).drop(\"rank\")\n",
        "top_products.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lUnWhIoUrFp",
        "outputId": "43ee593b-5006-4a77-f969-44a1245dd6be"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+-------------+-------------+\n",
            "|category_clean|product_clean|total_revenue|\n",
            "+--------------+-------------+-------------+\n",
            "|   Electronics|       Laptop|    962496295|\n",
            "|       Fashion|        Jeans|    951286127|\n",
            "|       Grocery|          Oil|    963572869|\n",
            "|          Home|       Vacuum|    959149427|\n",
            "+--------------+-------------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Identify the top 3 performing cities."
      ],
      "metadata": {
        "id": "OsX3hPfKUrhi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "city_ranked.filter(col(\"rank\") <= 3).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_afU3Xk_Ust3",
        "outputId": "c9956fd2-fc4e-4755-e980-0bc462e8ee73"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------------+----+\n",
            "|city_clean|total_revenue|rank|\n",
            "+----------+-------------+----+\n",
            "|      Pune|   1646196535|   1|\n",
            "| Hyderabad|   1642443340|   2|\n",
            "|     Delhi|   1639639916|   3|\n",
            "+----------+-------------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PHASE 7 – Broadcast Join\n",
        "\n"
      ],
      "metadata": {
        "id": "tLOcb6S2V0iY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "city_region = spark.createDataFrame([\n",
        "    (\"Delhi\", \"North\"),\n",
        "    (\"Mumbai\", \"West\"),\n",
        "    (\"Bangalore\", \"South\"),\n",
        "    (\"Hyderabad\", \"South\"),\n",
        "    (\"Pune\", \"West\"),\n",
        "    (\"Chennai\", \"South\"),\n",
        "    (\"Kolkata\", \"East\")\n",
        "], [\"city_clean\", \"region\"])"
      ],
      "metadata": {
        "id": "zjuCw8DZV8Qm"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Join the orders data with this city-region dataset.\n"
      ],
      "metadata": {
        "id": "5phILKwgWS5Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import broadcast\n",
        "orders_with_regions = orders_completed.join(broadcast(city_region), \"city_clean\")\n",
        "orders_with_regions.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAGRySG4Vr-_",
        "outputId": "9a3167eb-6e29-48e3-a83b-5d20e8ff2eda"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------+-----------+---------+-----------+-------+------+----------+---------+--------------+-------------+------------+----------------+------+\n",
            "|city_clean|   order_id|customer_id|     city|   category|product|amount|order_date|   status|category_clean|product_clean|amount_clean|order_date_clean|region|\n",
            "+----------+-----------+-----------+---------+-----------+-------+------+----------+---------+--------------+-------------+------------+----------------+------+\n",
            "|      Pune|ORD00000001|    C000001|     Pune|    Grocery|  Sugar| 35430|2024-01-02|Completed|       Grocery|        Sugar|       35430|      2024-01-02|  West|\n",
            "|      Pune|ORD00000007|    C000007|     Pune|    Grocery|   Rice| 45362|2024-01-08|Completed|       Grocery|         Rice|       45362|      2024-01-08|  West|\n",
            "| Bangalore|ORD00000008|    C000008|Bangalore|    Fashion|  Jeans| 10563|2024-01-09|Completed|       Fashion|        Jeans|       10563|      2024-01-09| South|\n",
            "| Bangalore|ORD00000010|    C000010|Bangalore|    Grocery|  Sugar| 66576|2024-01-11|Completed|       Grocery|        Sugar|       66576|      2024-01-11| South|\n",
            "|   Kolkata|ORD00000011|    C000011|  Kolkata|Electronics| Tablet| 50318|12/01/2024|Completed|   Electronics|       Tablet|       50318|      2024-01-12|  East|\n",
            "+----------+-----------+-----------+---------+-----------+-------+------+----------+---------+--------------+-------------+------------+----------------+------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Apply broadcast join explicitly.\n"
      ],
      "metadata": {
        "id": "_1iGV6ntWVj6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import broadcast\n",
        "orders_with_regions = orders_completed.join(broadcast(city_region), \"city_clean\")\n",
        "orders_with_regions.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKzwyvGlWXZa",
        "outputId": "a96cbe84-47d0-4825-8272-b8f32fa2ac4f"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------+-----------+---------+-----------+-------+------+----------+---------+--------------+-------------+------------+----------------+------+\n",
            "|city_clean|   order_id|customer_id|     city|   category|product|amount|order_date|   status|category_clean|product_clean|amount_clean|order_date_clean|region|\n",
            "+----------+-----------+-----------+---------+-----------+-------+------+----------+---------+--------------+-------------+------------+----------------+------+\n",
            "|      Pune|ORD00000001|    C000001|     Pune|    Grocery|  Sugar| 35430|2024-01-02|Completed|       Grocery|        Sugar|       35430|      2024-01-02|  West|\n",
            "|      Pune|ORD00000007|    C000007|     Pune|    Grocery|   Rice| 45362|2024-01-08|Completed|       Grocery|         Rice|       45362|      2024-01-08|  West|\n",
            "| Bangalore|ORD00000008|    C000008|Bangalore|    Fashion|  Jeans| 10563|2024-01-09|Completed|       Fashion|        Jeans|       10563|      2024-01-09| South|\n",
            "| Bangalore|ORD00000010|    C000010|Bangalore|    Grocery|  Sugar| 66576|2024-01-11|Completed|       Grocery|        Sugar|       66576|      2024-01-11| South|\n",
            "|   Kolkata|ORD00000011|    C000011|  Kolkata|Electronics| Tablet| 50318|12/01/2024|Completed|   Electronics|       Tablet|       50318|      2024-01-12|  East|\n",
            "+----------+-----------+-----------+---------+-----------+-------+------+----------+---------+--------------+-------------+------------+----------------+------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Verify using the physical plan that:\n",
        "\n",
        "BroadcastHashJoin\n",
        "\n",
        "is used.\n"
      ],
      "metadata": {
        "id": "bfMYuNC6WXwM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "orders_with_regions.explain(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MF7LCzOcWZqU",
        "outputId": "f0dcc54e-f703-43eb-b9c3-60bad31c6030"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Parsed Logical Plan ==\n",
            "'Join UsingJoin(Inner, [city_clean])\n",
            ":- Filter (status#24 = Completed)\n",
            ":  +- Deduplicate [order_id#17]\n",
            ":     +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#116, category_clean#117, product_clean#118, amount_clean#162, coalesce(cast(try_to_timestamp(order_date#23, Some(yyyy-MM-dd), TimestampType, Some(Etc/UTC), false) as date), cast(try_to_timestamp(order_date#23, Some(dd/MM/yyyy), TimestampType, Some(Etc/UTC), false) as date), cast(try_to_timestamp(order_date#23, Some(yyyy/MM/dd), TimestampType, Some(Etc/UTC), false) as date)) AS order_date_clean#315]\n",
            ":        +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#116, category_clean#117, product_clean#118, CASE WHEN RLIKE(amount_clean#161, ^[0-9]+$) THEN cast(amount_clean#161 as int) ELSE cast(null as int) END AS amount_clean#162]\n",
            ":           +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#116, category_clean#117, product_clean#118, regexp_replace(amount#22, ,, , 1) AS amount_clean#161]\n",
            ":              +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#116, category_clean#117, initcap(product_clean#73) AS product_clean#118]\n",
            ":                 +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#116, initcap(category_clean#72) AS category_clean#117, product_clean#73]\n",
            ":                    +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, initcap(city_clean#71) AS city_clean#116, category_clean#72, product_clean#73]\n",
            ":                       +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, category_clean#72, trim(product#21, None) AS product_clean#73]\n",
            ":                          +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, trim(category#20, None) AS category_clean#72]\n",
            ":                             +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, trim(city#19, None) AS city_clean#71]\n",
            ":                                +- Relation [order_id#17,customer_id#18,city#19,category#20,product#21,amount#22,order_date#23,status#24] csv\n",
            "+- ResolvedHint (strategy=broadcast)\n",
            "   +- LogicalRDD [city_clean#2388, region#2389], false\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "city_clean: string, order_id: string, customer_id: string, city: string, category: string, product: string, amount: string, order_date: string, status: string, category_clean: string, product_clean: string, amount_clean: int, order_date_clean: date, region: string\n",
            "Project [city_clean#116, order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, category_clean#117, product_clean#118, amount_clean#162, order_date_clean#315, region#2389]\n",
            "+- Join Inner, (city_clean#116 = city_clean#2388)\n",
            "   :- Filter (status#24 = Completed)\n",
            "   :  +- Deduplicate [order_id#17]\n",
            "   :     +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#116, category_clean#117, product_clean#118, amount_clean#162, coalesce(cast(try_to_timestamp(order_date#23, Some(yyyy-MM-dd), TimestampType, Some(Etc/UTC), false) as date), cast(try_to_timestamp(order_date#23, Some(dd/MM/yyyy), TimestampType, Some(Etc/UTC), false) as date), cast(try_to_timestamp(order_date#23, Some(yyyy/MM/dd), TimestampType, Some(Etc/UTC), false) as date)) AS order_date_clean#315]\n",
            "   :        +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#116, category_clean#117, product_clean#118, CASE WHEN RLIKE(amount_clean#161, ^[0-9]+$) THEN cast(amount_clean#161 as int) ELSE cast(null as int) END AS amount_clean#162]\n",
            "   :           +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#116, category_clean#117, product_clean#118, regexp_replace(amount#22, ,, , 1) AS amount_clean#161]\n",
            "   :              +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#116, category_clean#117, initcap(product_clean#73) AS product_clean#118]\n",
            "   :                 +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#116, initcap(category_clean#72) AS category_clean#117, product_clean#73]\n",
            "   :                    +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, initcap(city_clean#71) AS city_clean#116, category_clean#72, product_clean#73]\n",
            "   :                       +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, category_clean#72, trim(product#21, None) AS product_clean#73]\n",
            "   :                          +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, trim(category#20, None) AS category_clean#72]\n",
            "   :                             +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, trim(city#19, None) AS city_clean#71]\n",
            "   :                                +- Relation [order_id#17,customer_id#18,city#19,category#20,product#21,amount#22,order_date#23,status#24] csv\n",
            "   +- ResolvedHint (strategy=broadcast)\n",
            "      +- LogicalRDD [city_clean#2388, region#2389], false\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Project [city_clean#2747, order_id#17, customer_id#2733, city#2735, category#2737, product#2739, amount#2741, order_date#2743, status#2745, category_clean#2749, product_clean#2751, amount_clean#2753, order_date_clean#2755, region#2389]\n",
            "+- Join Inner, (city_clean#2747 = city_clean#2388), rightHint=(strategy=broadcast)\n",
            "   :- Filter ((isnotnull(status#2745) AND (status#2745 = Completed)) AND isnotnull(city_clean#2747))\n",
            "   :  +- Aggregate [order_id#17], [order_id#17, first(customer_id#18, false) AS customer_id#2733, first(city#19, false) AS city#2735, first(category#20, false) AS category#2737, first(product#21, false) AS product#2739, first(amount#22, false) AS amount#2741, first(order_date#23, false) AS order_date#2743, first(status#24, false) AS status#2745, first(city_clean#116, false) AS city_clean#2747, first(category_clean#117, false) AS category_clean#2749, first(product_clean#118, false) AS product_clean#2751, first(amount_clean#162, false) AS amount_clean#2753, first(order_date_clean#315, false) AS order_date_clean#2755]\n",
            "   :     +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#116, category_clean#117, product_clean#118, CASE WHEN RLIKE(amount_clean#161, ^[0-9]+$) THEN cast(amount_clean#161 as int) END AS amount_clean#162, coalesce(cast(gettimestamp(order_date#23, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#23, dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#23, yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date)) AS order_date_clean#315]\n",
            "   :        +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, initcap(trim(city#19, None)) AS city_clean#116, initcap(trim(category#20, None)) AS category_clean#117, initcap(trim(product#21, None)) AS product_clean#118, regexp_replace(amount#22, ,, , 1) AS amount_clean#161]\n",
            "   :           +- Relation [order_id#17,customer_id#18,city#19,category#20,product#21,amount#22,order_date#23,status#24] csv\n",
            "   +- Filter isnotnull(city_clean#2388)\n",
            "      +- LogicalRDD [city_clean#2388, region#2389], false\n",
            "\n",
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- Project [city_clean#2747, order_id#17, customer_id#2733, city#2735, category#2737, product#2739, amount#2741, order_date#2743, status#2745, category_clean#2749, product_clean#2751, amount_clean#2753, order_date_clean#2755, region#2389]\n",
            "   +- BroadcastHashJoin [city_clean#2747], [city_clean#2388], Inner, BuildRight, false\n",
            "      :- Filter ((isnotnull(status#2745) AND (status#2745 = Completed)) AND isnotnull(city_clean#2747))\n",
            "      :  +- SortAggregate(key=[order_id#17], functions=[first(customer_id#18, false), first(city#19, false), first(category#20, false), first(product#21, false), first(amount#22, false), first(order_date#23, false), first(status#24, false), first(city_clean#116, false), first(category_clean#117, false), first(product_clean#118, false), first(amount_clean#162, false), first(order_date_clean#315, false)], output=[order_id#17, customer_id#2733, city#2735, category#2737, product#2739, amount#2741, order_date#2743, status#2745, city_clean#2747, category_clean#2749, product_clean#2751, amount_clean#2753, order_date_clean#2755])\n",
            "      :     +- Sort [order_id#17 ASC NULLS FIRST], false, 0\n",
            "      :        +- Exchange hashpartitioning(order_id#17, 200), ENSURE_REQUIREMENTS, [plan_id=3595]\n",
            "      :           +- SortAggregate(key=[order_id#17], functions=[partial_first(customer_id#18, false), partial_first(city#19, false), partial_first(category#20, false), partial_first(product#21, false), partial_first(amount#22, false), partial_first(order_date#23, false), partial_first(status#24, false), partial_first(city_clean#116, false), partial_first(category_clean#117, false), partial_first(product_clean#118, false), partial_first(amount_clean#162, false), partial_first(order_date_clean#315, false)], output=[order_id#17, first#2780, valueSet#2781, first#2782, valueSet#2783, first#2784, valueSet#2785, first#2786, valueSet#2787, first#2788, valueSet#2789, first#2790, valueSet#2791, first#2792, valueSet#2793, first#2794, valueSet#2795, first#2796, valueSet#2797, first#2798, valueSet#2799, first#2800, valueSet#2801, first#2802, valueSet#2803])\n",
            "      :              +- Sort [order_id#17 ASC NULLS FIRST], false, 0\n",
            "      :                 +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#116, category_clean#117, product_clean#118, CASE WHEN RLIKE(amount_clean#161, ^[0-9]+$) THEN cast(amount_clean#161 as int) END AS amount_clean#162, coalesce(cast(gettimestamp(order_date#23, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#23, dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#23, yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date)) AS order_date_clean#315]\n",
            "      :                    +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, initcap(trim(city#19, None)) AS city_clean#116, initcap(trim(category#20, None)) AS category_clean#117, initcap(trim(product#21, None)) AS product_clean#118, regexp_replace(amount#22, ,, , 1) AS amount_clean#161]\n",
            "      :                       +- FileScan csv [order_id#17,customer_id#18,city#19,category#20,product#21,amount#22,order_date#23,status#24] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/content/orders.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<order_id:string,customer_id:string,city:string,category:string,product:string,amount:strin...\n",
            "      +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, false]),false), [plan_id=3600]\n",
            "         +- Filter isnotnull(city_clean#2388)\n",
            "            +- Scan ExistingRDD[city_clean#2388,region#2389]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Explain why broadcast join is efficient in this case."
      ],
      "metadata": {
        "id": "jSSKz59CWZ_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#small lookup table\n",
        "#avoids shuffle\n",
        "#sent to all executors\n",
        "#faster joins at scale"
      ],
      "metadata": {
        "id": "YHNelZOjWavN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PHASE 8 – UDF\n",
        "\n"
      ],
      "metadata": {
        "id": "6v1AzFpQW2Ay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a classification based on amount:\n",
        "\n",
        "amount >= 80000 → High\n",
        "amount >= 40000 → Medium\n",
        "else → Low\n",
        "\n",
        "Add a new column:\n",
        "\n",
        "order_value_category\n",
        "\n",
        "Analyze distribution."
      ],
      "metadata": {
        "id": "4EDS-XrjW5j9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "orders_classified = orders_with_regions\\\n",
        ".withColumn(\n",
        "    \"order_value_category\",\n",
        "    when(col(\"amount_clean\") >= 80000, \"High\")\\\n",
        "    .when(col(\"amount_clean\") >= 40000, \"Medium\")\\\n",
        "    .otherwise(\"Low\")\n",
        ")\n",
        "orders_classified.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pcfy2kuQW6TS",
        "outputId": "ab667b24-13ff-4d87-bbec-f47517544837"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------+-----------+---------+-----------+-------+------+----------+---------+--------------+-------------+------------+----------------+------+--------------------+\n",
            "|city_clean|   order_id|customer_id|     city|   category|product|amount|order_date|   status|category_clean|product_clean|amount_clean|order_date_clean|region|order_value_category|\n",
            "+----------+-----------+-----------+---------+-----------+-------+------+----------+---------+--------------+-------------+------------+----------------+------+--------------------+\n",
            "|      Pune|ORD00000001|    C000001|     Pune|    Grocery|  Sugar| 35430|2024-01-02|Completed|       Grocery|        Sugar|       35430|      2024-01-02|  West|                 Low|\n",
            "|      Pune|ORD00000007|    C000007|     Pune|    Grocery|   Rice| 45362|2024-01-08|Completed|       Grocery|         Rice|       45362|      2024-01-08|  West|              Medium|\n",
            "| Bangalore|ORD00000008|    C000008|Bangalore|    Fashion|  Jeans| 10563|2024-01-09|Completed|       Fashion|        Jeans|       10563|      2024-01-09| South|                 Low|\n",
            "| Bangalore|ORD00000010|    C000010|Bangalore|    Grocery|  Sugar| 66576|2024-01-11|Completed|       Grocery|        Sugar|       66576|      2024-01-11| South|              Medium|\n",
            "|   Kolkata|ORD00000011|    C000011|  Kolkata|Electronics| Tablet| 50318|12/01/2024|Completed|   Electronics|       Tablet|       50318|      2024-01-12|  East|              Medium|\n",
            "+----------+-----------+-----------+---------+-----------+-------+------+----------+---------+--------------+-------------+------------+----------------+------+--------------------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "orders_classified.groupBy(\"order_value_category\").count().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CC7FJSJtXkfR",
        "outputId": "e0a2af10-2232-453b-8d86-27d76533cfbe"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------+\n",
            "|order_value_category| count|\n",
            "+--------------------+------+\n",
            "|                High| 27936|\n",
            "|                 Low|145699|\n",
            "|              Medium|111365|\n",
            "+--------------------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PHASE 9 – RDD\n"
      ],
      "metadata": {
        "id": "XwBS1yQKXpWc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Convert the cleaned DataFrame to RDD.\n"
      ],
      "metadata": {
        "id": "YECA2PVXXuiU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "orders_rdd = orders_completed.select(\"city_clean\", \"amount_clean\").rdd"
      ],
      "metadata": {
        "id": "zTsekk0xX4QI"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Compute:\n",
        "Total revenue using reduce.\n",
        "Orders per city using map and reduce.\n"
      ],
      "metadata": {
        "id": "ZBaQqVrjXxFf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_revenue = orders_rdd.map(lambda x: x[1] if x[1] is not None else 0).reduce(lambda x, y: x + y)\n",
        "print(\"Total revenue:\", total_revenue)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyavq31UXzVd",
        "outputId": "a7188746-60e3-4829-b074-981a7f076068"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total revenue: 11436490724\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Explain why DataFrames are preferred over RDDs for analytics."
      ],
      "metadata": {
        "id": "uroC095rXzq9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#DataFrames are faster and optimized using Catalyst and Tungsten.\n",
        "#Support SQL queries and rich built-in functions.\n",
        "#Schema enforcement ensures structured data and better performance.\n",
        "#Columnar storage improves memory and speed."
      ],
      "metadata": {
        "id": "QCp558AEX0Rd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PHASE 10 – Caching\n"
      ],
      "metadata": {
        "id": "9uVJSFVkYWqf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Identify datasets reused in multiple queries.\n"
      ],
      "metadata": {
        "id": "Zr8OkZmqYfPv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Datasets heavily reused in multiple queries:\n",
        "# 1. orders_completed: Used for all analytics (Phase 5), window functions (Phase 6), broadcast joins (Phase 7), UDF (Phase 8), and RDD conversions (Phase 9).\n",
        "# 2. city_revenue: Derived from orders_completed and then used for ranking cities (Phase 6) and sorting (Phase 5).\n",
        "\n",
        "print(\"Datasets identified for potential caching:\")\n",
        "print(\"- orders_completed (used extensively for analytics, joins, and RDD operations)\")\n",
        "print(\"- city_revenue (used for further analysis and window functions)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dubFDcpGYeUd",
        "outputId": "15417b76-9f56-49eb-c9d3-afc876d945ec"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datasets identified for potential caching:\n",
            "- orders_completed (used extensively for analytics, joins, and RDD operations)\n",
            "- city_revenue (used for further analysis and window functions)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Apply cache().\n"
      ],
      "metadata": {
        "id": "Jovx17ZrYgwa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "orders_completed.cache()\n",
        "city_revenue.cache()\n",
        "\n",
        "print(\"orders_completed DataFrame is cached:\", orders_completed.is_cached)\n",
        "print(\"city_revenue DataFrame is cached:\", city_revenue.is_cached)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJWNmscXYiZU",
        "outputId": "e8bfcace-4b6c-4e8d-ca45-1f8d16386164"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "orders_completed DataFrame is cached: True\n",
            "city_revenue DataFrame is cached: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Execute multiple aggregations.\n"
      ],
      "metadata": {
        "id": "63WgXJSnYivi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Executing aggregations on cached DataFrames...\")\n",
        "\n",
        "# Aggregation 1: Total revenue per category (on cached orders_completed)\n",
        "orders_completed.groupBy(\"category_clean\").agg(sum(\"amount_clean\").alias(\"total_revenue\")).show(5)\n",
        "\n",
        "# Aggregation 2: Average order value per city (on cached orders_completed)\n",
        "orders_completed.groupBy(\"city_clean\").agg(avg(\"amount_clean\").alias(\"avg_order_value\")).show(5)\n",
        "\n",
        "# Aggregation 3: Max revenue per city (on cached city_revenue, which itself is cached)\n",
        "city_revenue.agg(max(\"total_revenue\")).show()\n",
        "\n",
        "print(\"Aggregations executed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dopda89AYkYs",
        "outputId": "23ff6f77-4c0d-44ab-96a5-388494a688b2"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Executing aggregations on cached DataFrames...\n",
            "+--------------+-------------+\n",
            "|category_clean|total_revenue|\n",
            "+--------------+-------------+\n",
            "|          Home|   2868467576|\n",
            "|       Fashion|   2834182172|\n",
            "|       Grocery|   2866272106|\n",
            "|   Electronics|   2867568870|\n",
            "+--------------+-------------+\n",
            "\n",
            "+----------+------------------+\n",
            "|city_clean|   avg_order_value|\n",
            "+----------+------------------+\n",
            "| Bangalore|44098.867908689645|\n",
            "|   Chennai| 43628.27900315863|\n",
            "|    Mumbai| 43723.75651612556|\n",
            "|   Kolkata|43709.816662630175|\n",
            "|      Pune|43930.204013556424|\n",
            "+----------+------------------+\n",
            "only showing top 5 rows\n",
            "+------------------+\n",
            "|max(total_revenue)|\n",
            "+------------------+\n",
            "|        1646196535|\n",
            "+------------------+\n",
            "\n",
            "Aggregations executed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Compare performance.\n"
      ],
      "metadata": {
        "id": "R58U9RZJYl5J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "print(\"--- Comparing Performance of Cached vs. Uncached DataFrames ---\")\n",
        "\n",
        "# Unpersist DataFrames first to ensure a clean comparison\n",
        "orders_completed.unpersist()\n",
        "city_revenue.unpersist()\n",
        "print(\"\\nDataFrames unpersisted for baseline comparison.\")\n",
        "\n",
        "# --- Baseline: Execute aggregations without caching ---\n",
        "print(\"\\nExecuting aggregations WITHOUT caching...\")\n",
        "start_time_uncached = time.time()\n",
        "\n",
        "orders_completed.groupBy(\"category_clean\").agg(sum(\"amount_clean\").alias(\"total_revenue\")).collect()\n",
        "orders_completed.groupBy(\"city_clean\").agg(avg(\"amount_clean\").alias(\"avg_order_value\")).collect()\n",
        "city_revenue.agg(max(\"total_revenue\")).collect()\n",
        "\n",
        "end_time_uncached = time.time()\n",
        "duration_uncached = end_time_uncached - start_time_uncached\n",
        "print(f\"Aggregations WITHOUT caching took: {duration_uncached:.4f} seconds\")\n",
        "\n",
        "# --- Re-cache DataFrames ---\n",
        "orders_completed.cache()\n",
        "city_revenue.cache()\n",
        "# Trigger caching with an action\n",
        "orders_completed.count()\n",
        "city_revenue.count()\n",
        "print(\"\\nDataFrames re-cached.\")\n",
        "\n",
        "# --- Cached: Execute aggregations WITH caching ---\n",
        "print(\"\\nExecuting aggregations WITH caching...\")\n",
        "start_time_cached = time.time()\n",
        "\n",
        "orders_completed.groupBy(\"category_clean\").agg(sum(\"amount_clean\").alias(\"total_revenue\")).collect()\n",
        "orders_completed.groupBy(\"city_clean\").agg(avg(\"amount_clean\").alias(\"avg_order_value\")).collect()\n",
        "city_revenue.agg(max(\"total_revenue\")).collect()\n",
        "\n",
        "end_time_cached = time.time()\n",
        "duration_cached = end_time_cached - start_time_cached\n",
        "print(f\"Aggregations WITH caching took: {duration_cached:.4f} seconds\")\n",
        "\n",
        "print(\"\\nPerformance Comparison:\")\n",
        "print(f\"Uncached duration: {duration_uncached:.4f} seconds\")\n",
        "print(f\"Cached duration:   {duration_cached:.4f} seconds\")\n",
        "if duration_uncached > 0:\n",
        "    speedup = duration_uncached / duration_cached\n",
        "    print(f\"Caching provided a speedup of approximately {speedup:.2f}x\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnGhfppdYo4M",
        "outputId": "3874d5c1-ba33-44f6-d929-6afb4712aa55"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Comparing Performance of Cached vs. Uncached DataFrames ---\n",
            "\n",
            "DataFrames unpersisted for baseline comparison.\n",
            "\n",
            "Executing aggregations WITHOUT caching...\n",
            "Aggregations WITHOUT caching took: 8.5717 seconds\n",
            "\n",
            "DataFrames re-cached.\n",
            "\n",
            "Executing aggregations WITH caching...\n",
            "Aggregations WITH caching took: 7.1447 seconds\n",
            "\n",
            "Performance Comparison:\n",
            "Uncached duration: 8.5717 seconds\n",
            "Cached duration:   7.1447 seconds\n",
            "Caching provided a speedup of approximately 1.20x\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Unpersist after use.\n",
        "Explain why unnecessary caching is dangerous."
      ],
      "metadata": {
        "id": "5w5M_JjJYpL3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "orders_completed.unpersist()\n",
        "#memory pressure\n",
        "#executor oom\n",
        "#cache eviction\n",
        "#slower jobs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7P1b_lCkYp03",
        "outputId": "90068f04-426c-457f-c1dd-74c1b97a7452"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[order_id: string, customer_id: string, city: string, category: string, product: string, amount: string, order_date: string, status: string, city_clean: string, category_clean: string, product_clean: string, amount_clean: int, order_date_clean: date]"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PHASE 11 – Storage Formats\n"
      ],
      "metadata": {
        "id": "vAFZ20T_ZeGB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Write cleaned dataset to:\n",
        "\n",
        "Parquet\n",
        "\n",
        "Partitioned by:\n",
        "\n",
        "city\n",
        "\n"
      ],
      "metadata": {
        "id": "OU9eSzsYZmSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "orders_completed.write.mode(\"overwrite\").partitionBy(\"city_clean\").parquet(\"orders_parquet\")"
      ],
      "metadata": {
        "id": "mO0-K2M1ZoD_"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Write aggregated datasets to:\n",
        "\n",
        "ORC\n",
        "\n"
      ],
      "metadata": {
        "id": "0r31gNDLZob5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "city_revenue.write.mode(\"overwrite\").orc(\"city_revenue_orc\")"
      ],
      "metadata": {
        "id": "A0iS8j0yZqA8"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Read both formats back and validate:\n",
        "Schema\n",
        "Row counts\n"
      ],
      "metadata": {
        "id": "lHB-ESr2ZqbB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.read.parquet(\"orders_parquet\").printSchema()\n",
        "spark.read.parquet(\"orders_parquet\").count()\n",
        "spark.read.orc(\"city_revenue_orc\").printSchema()\n",
        "spark.read.orc(\"city_revenue_orc\").count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OR8PgDNEZsAf",
        "outputId": "e898c7db-19a2-44ac-8337-6b2b268da2f9"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- order_id: string (nullable = true)\n",
            " |-- customer_id: string (nullable = true)\n",
            " |-- city: string (nullable = true)\n",
            " |-- category: string (nullable = true)\n",
            " |-- product: string (nullable = true)\n",
            " |-- amount: string (nullable = true)\n",
            " |-- order_date: string (nullable = true)\n",
            " |-- status: string (nullable = true)\n",
            " |-- category_clean: string (nullable = true)\n",
            " |-- product_clean: string (nullable = true)\n",
            " |-- amount_clean: integer (nullable = true)\n",
            " |-- order_date_clean: date (nullable = true)\n",
            " |-- city_clean: string (nullable = true)\n",
            "\n",
            "root\n",
            " |-- city_clean: string (nullable = true)\n",
            " |-- total_revenue: long (nullable = true)\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Compare size and performance against CSV."
      ],
      "metadata": {
        "id": "tBiha4XJZsZC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import builtins # Import builtins module to access Python's built-in functions explicitly\n",
        "\n",
        "# --- File Size Comparison ---\n",
        "print(\"\\n--- File Size Comparison ---\")\n",
        "\n",
        "csv_file_size = os.path.getsize(\"orders.csv\")\n",
        "parquet_dir_size = builtins.sum(f.stat().st_size for f in os.scandir(\"orders_parquet\") if f.is_file())\n",
        "orc_dir_size = builtins.sum(f.stat().st_size for f in os.scandir(\"city_revenue_orc\") if f.is_file())\n",
        "\n",
        "print(f\"CSV (orders.csv) size: {csv_file_size / (1024*1024):.2f} MB\")\n",
        "print(f\"Parquet (orders_parquet) directory size: {parquet_dir_size / (1024*1024):.2f} MB\")\n",
        "print(f\"ORC (city_revenue_orc) directory size: {orc_dir_size / (1024*1024):.2f} MB\")\n",
        "\n",
        "# --- Read Performance Comparison ---\n",
        "print(\"\\n--- Read Performance Comparison ---\")\n",
        "\n",
        "# CSV Read Time\n",
        "start_time = time.time()\n",
        "spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"false\").csv(\"orders.csv\").count()\n",
        "end_time = time.time()\n",
        "print(f\"CSV read time: {end_time - start_time:.4f} seconds\")\n",
        "\n",
        "# Parquet Read Time\n",
        "start_time = time.time()\n",
        "spark.read.parquet(\"orders_parquet\").count()\n",
        "end_time = time.time()\n",
        "print(f\"Parquet read time: {end_time - start_time:.4f} seconds\")\n",
        "\n",
        "# ORC Read Time\n",
        "start_time = time.time()\n",
        "spark.read.orc(\"city_revenue_orc\").count()\n",
        "end_time = time.time()\n",
        "print(f\"ORC read time: {end_time - start_time:.4f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7Xh_ER1ZtC9",
        "outputId": "51e0f601-46ee-4c54-ec43-01bb8d130e66"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- File Size Comparison ---\n",
            "CSV (orders.csv) size: 19.98 MB\n",
            "Parquet (orders_parquet) directory size: 0.00 MB\n",
            "ORC (city_revenue_orc) directory size: 0.00 MB\n",
            "\n",
            "--- Read Performance Comparison ---\n",
            "CSV read time: 0.7060 seconds\n",
            "Parquet read time: 0.3689 seconds\n",
            "ORC read time: 0.1949 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PHASE 12 – Debugging\n"
      ],
      "metadata": {
        "id": "2PhXUSHgahFB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explain why this breaks:\n",
        "\n",
        "df = df.filter(df.amount > 50000).show()\n",
        "\n",
        "And why after this line df is no longer a DataFrame."
      ],
      "metadata": {
        "id": "lLVVf6sHajY2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#The explanation for why df = df.filter(df.amount > 50000).show() breaks, and why df is no longer a DataFrame afterward, can be found in cell OU_cAY0uangU. It details the distinction between Spark transformations and actions, and how the show() action returns None, leading to reassignment of df to NoneType."
      ],
      "metadata": {
        "id": "OU_cAY0uangU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PHASE 13 – Final Validation\n"
      ],
      "metadata": {
        "id": "Ye_9N6_Pa5ae"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Confirm:\n",
        "\n",
        "amount is IntegerType\n",
        "\n",
        "order_date_clean is DateType\n",
        "\n",
        "No nulls in critical business fields.\n"
      ],
      "metadata": {
        "id": "XQ1pZORea7dG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Final Data Validation ---\")\n",
        "\n",
        "# Confirm amount_clean is IntegerType and order_date_clean is DateType\n",
        "print(\"\\nSchema verification for critical columns:\")\n",
        "orders_completed.select(\"amount_clean\", \"order_date_clean\").printSchema()\n",
        "\n",
        "# Check for nulls in critical business fields (amount_clean, order_date_clean)\n",
        "print(\"\\nChecking for nulls in critical business fields (amount_clean, order_date_clean):\")\n",
        "\n",
        "# For amount_clean\n",
        "null_amount_count = orders_completed.filter(col(\"amount_clean\").isNull()).count()\n",
        "print(f\"Number of records with null amount_clean: {null_amount_count}\")\n",
        "\n",
        "# For order_date_clean\n",
        "null_order_date_count = orders_completed.filter(col(\"order_date_clean\").isNull()).count()\n",
        "print(f\"Number of records with null order_date_clean: {null_order_date_count}\")\n",
        "\n",
        "if null_amount_count == 0 and null_order_date_count == 0:\n",
        "    print(\"\\nValidation successful: No nulls found in amount_clean or order_date_clean.\")\n",
        "else:\n",
        "    print(\"\\nValidation Alert: Nulls found in critical business fields.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqcHajYna9eJ",
        "outputId": "91173058-439c-4a9f-c884-904209d9aaf3"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Final Data Validation ---\n",
            "\n",
            "Schema verification for critical columns:\n",
            "root\n",
            " |-- amount_clean: integer (nullable = true)\n",
            " |-- order_date_clean: date (nullable = true)\n",
            "\n",
            "\n",
            "Checking for nulls in critical business fields (amount_clean, order_date_clean):\n",
            "Number of records with null amount_clean: 23905\n",
            "Number of records with null order_date_clean: 2465\n",
            "\n",
            "Validation Alert: Nulls found in critical business fields.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Document:\n",
        "\n",
        "Cleaning strategy\n",
        "\n",
        "Performance strategy\n",
        "\n",
        "Debugging learnings"
      ],
      "metadata": {
        "id": "kvlx1qiOa92v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Strategies and Learnings\n",
        "#1. Cleaning Strategy\n",
        "\n",
        "#StringType Ingestion: Load all columns as StringType to avoid schema inference issues and ensure complete data capture.\n",
        "#Text Standardization: Trim spaces and apply proper case to city, category, and product columns.\n",
        "#Amount Cleaning: Remove commas, validate numeric strings, cast to IntegerType; invalid values → NULL.\n",
        "#Date Handling: Use coalesce with try_to_timestamp for multiple formats; unparseable dates → NULL.\n",
        "#Preserve Raw Data: Create _clean columns for traceability.\n",
        "#Deduplication: Remove duplicates based on order_id.\n",
        "#Filter Valid Status: Keep only status = 'Completed'.\n",
        "\n",
        "#2. Performance Strategy\n",
        "\n",
        "#Partitioning: Monitor and repartition by common keys (e.g., city) to reduce shuffle.\n",
        "#Broadcast Join: Use broadcast() for small lookup tables to avoid shuffling large DataFrames.\n",
        "#Caching: Cache reused DataFrames for faster queries; demonstrated ~1.2x speedup.\n",
        "#Unpersist: Free memory after use to prevent OOM issues.\n",
        "\n",
        "#3. Debugging Learnings\n",
        "\n",
        "#when().otherwise(): Ensure correct syntax and nesting.\n",
        "#Date Parsing: Use try_to_timestamp instead of strict to_date.\n",
        "#lit() for Constants: Wrap string literals to avoid AnalysisException.\n",
        "#SQL Execution: Use spark.sql(\"query\"), not spark.sql.session.sql().\n",
        "#show() Behavior: show() is an action, returns None—don’t reassign DataFrame.\n",
        "#sum() Conflict: Differentiate Python’s sum() vs PySpark’s sum().\n",
        "#Handle None in RDDs: Replace None with defaults before aggregation."
      ],
      "metadata": {
        "id": "p7X_prUJa-2V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}